{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install matplotlib\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X52W1oNdDg8T",
        "outputId": "995731b6-fa79-48af-dede-1db097344c02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4jIK9pWDfU0"
      },
      "source": [
        "# Define the Vision Transfomer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "TJ-t9dPNDfU1",
        "outputId": "ce95853f-8a7e-470d-cd2d-c9a2edbe0760"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moscar-ovanger\u001b[0m (\u001b[33moscars\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241129_132350-h4rv6va2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/oscars/vision-transformer-toy-example/runs/h4rv6va2' target=\"_blank\">icy-morning-1</a></strong> to <a href='https://wandb.ai/oscars/vision-transformer-toy-example' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/oscars/vision-transformer-toy-example' target=\"_blank\">https://wandb.ai/oscars/vision-transformer-toy-example</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/oscars/vision-transformer-toy-example/runs/h4rv6va2' target=\"_blank\">https://wandb.ai/oscars/vision-transformer-toy-example/runs/h4rv6va2</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, feedforward_dim, num_layers, num_tokens, max_patches, dropout=0.0, hidden_dim=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Create the embedding matrix for 2-cell binary combinations + 1 mask token\n",
        "        embedding_matrix = torch.zeros((num_tokens, embed_dim))  # Shape: (num_tokens, embed_dim)\n",
        "\n",
        "        # Generate all possible 2-cell binary patches\n",
        "        patches = torch.tensor([\n",
        "            [a, b]\n",
        "            for a in range(2)\n",
        "            for b in range(2)\n",
        "        ])  # Shape: (4, 2) for 4 combinations of 2-cell binary patches\n",
        "\n",
        "        # Assign each patch's values as its embedding\n",
        "        for i, patch in enumerate(patches):\n",
        "            embedding_matrix[i, :] = patch  # Set the embedding to the patch values\n",
        "\n",
        "        # Set the last row to all 2s for the masked token\n",
        "        embedding_matrix[-1, :] = 0.5  # Mask token embedding\n",
        "\n",
        "        # Create embedding layer\n",
        "        self.embedding_matrix = nn.Embedding.from_pretrained(\n",
        "            embedding_matrix, freeze=True\n",
        "        )\n",
        "\n",
        "        # Transformer encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(hidden_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Load hidden_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Linear layer to project input embeddings\n",
        "        self.input_proj = nn.Linear(embed_dim, self.hidden_dim)\n",
        "\n",
        "        # Positional embeddings\n",
        "        self.positional_embedding = nn.Parameter(torch.randn(max_patches, 1, self.hidden_dim))  # Shape: (seq_len, 1, hidden_dim)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc_out = nn.Linear(self.hidden_dim, num_tokens-1)\n",
        "\n",
        "    def forward(self, patches):\n",
        "        # Retrieve embeddings\n",
        "        embeddings = self.embedding_matrix(patches)  # (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        # Prepare input for transformer layers\n",
        "        x = embeddings.permute(1, 0, 2)  # (seq_len, batch_size, embed_dim)\n",
        "\n",
        "        # Extract seq_len and batch_size\n",
        "        seq_len, batch_size, _ = x.size()\n",
        "\n",
        "        # Project input to hidden_dim\n",
        "        z = self.input_proj(x)  # Shape: (seq_len, batch_size, hidden_dim)\n",
        "\n",
        "        # Add positional embedding\n",
        "        pos_emb = self.positional_embedding[:seq_len, :, :].expand(-1, batch_size, -1)  # Shape: (seq_len, batch_size, hidden_dim)\n",
        "        z = z + pos_emb\n",
        "\n",
        "        # Pass through transformer layers\n",
        "        for layer in self.encoder_layers:\n",
        "            z = layer(z)\n",
        "\n",
        "        # Output logits\n",
        "        z = z.permute(1, 0, 2)  # Back to (batch_size, seq_len, hidden_dim)\n",
        "        logits = self.fc_out(z)  # (batch_size, seq_len, num_tokens-1)\n",
        "        return logits\n",
        "\n",
        "    def get_probabilities(self, logits):\n",
        "        \"\"\"Compute probabilities using softmax.\"\"\"\n",
        "        return torch.softmax(logits, dim=-1)\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads, feedforward_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Ensure hidden_dim is divisible by num_heads\n",
        "        assert self.hidden_dim % self.num_heads == 0, \"Hidden dimension must be divisible by the number of heads.\"\n",
        "\n",
        "        # Multi-head attention\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=self.hidden_dim, num_heads=num_heads, dropout=dropout)\n",
        "\n",
        "        # Feedforward network\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, self.hidden_dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # Layer normalization\n",
        "        self.norm1 = nn.LayerNorm(self.hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(self.hidden_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            z: Tensor of shape (seq_len, batch_size, hidden_dim)\n",
        "        Returns:\n",
        "            Tensor of shape (seq_len, batch_size, hidden_dim)\n",
        "        \"\"\"\n",
        "        seq_len, batch_size, hidden_dim = z.size()\n",
        "\n",
        "        # Apply LayerNorm\n",
        "        z_norm = self.norm1(z)\n",
        "\n",
        "        # Self-attention\n",
        "        attn_output, _ = self.attention(z_norm, z_norm, z_norm)  # Shape: (seq_len, batch_size, hidden_dim)\n",
        "\n",
        "        # Residual connection\n",
        "        z = z + self.dropout(attn_output)\n",
        "\n",
        "        # Feedforward layer\n",
        "        z_norm = self.norm2(z)\n",
        "        feedforward_output = self.feedforward(z_norm)\n",
        "\n",
        "        # Final residual connection\n",
        "        z = z + self.dropout(feedforward_output)\n",
        "\n",
        "        return z\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Toy Dataset: 100 Binary 4x4 Images\n",
        "images = torch.randint(0, 2, (100, 4, 4)).long()\n",
        "\n",
        "# Plot the first 10 images in a 5x2 subplot\n",
        "fig, axs = plt.subplots(2, 5, figsize=(10, 4))\n",
        "fig.suptitle(\"10 First Realizations of Dataset\", fontsize=16)\n",
        "\n",
        "for idx, ax in enumerate(axs.flat):  # Flatten the 2D array of axes for easy iteration\n",
        "    ax.imshow(images[idx].numpy(), cmap=\"gray\")\n",
        "    ax.set_title(f\"Image {idx + 1}\")\n",
        "    ax.axis(\"off\")  # Turn off the axes for cleaner visualization\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title\n",
        "plt.show()\n",
        "\n",
        "import wandb\n",
        "# Parameters\n",
        "batch_size = 1\n",
        "embed_dim = 2\n",
        "hidden_dim = 3\n",
        "num_heads = 1\n",
        "feedforward_dim = hidden_dim*2  # (2-4)\n",
        "num_layers = 1\n",
        "num_tokens = 5  # 4 tokens + 1 mask token\n",
        "max_patches = 8\n",
        "dropout = 0.2\n",
        "learning_rate = 3e-4\n",
        "num_epochs = 100\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.login()\n",
        "wandb.init(\n",
        "    project=\"vision-transformer-toy-example\",\n",
        "    config={\n",
        "        \"batch_size\": batch_size,\n",
        "        \"embed_dim\": embed_dim,\n",
        "        \"num_heads\": num_heads,\n",
        "        \"feedforward_dim\": feedforward_dim,\n",
        "        \"num_layers\": num_layers,\n",
        "        \"num_tokens\": num_tokens,\n",
        "        \"max_patches\": max_patches,\n",
        "        \"dropout\": dropout,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"num_epochs\": num_epochs,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model\n",
        "model = VisionTransformer(embed_dim, num_heads, feedforward_dim, num_layers, num_tokens, max_patches, dropout, hidden_dim).to(device)\n",
        "#model.load_state_dict(checkpoint)  # Load model weights\n",
        "# Optimizer and Loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Dataloader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "class BinaryImageDataset(Dataset):\n",
        "    def __init__(self, images):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images (Tensor): Tensor of shape (num_images, 64, 64) with binary values (0 or 1).\n",
        "        \"\"\"\n",
        "        self.images = images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        return torch.tensor(image, dtype=torch.float32)\n",
        "\n",
        "dataset = BinaryImageDataset(images)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "X2gi7ds3Gvww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    current_mask_rate = 0.5\n",
        "\n",
        "    for batch_idx, images in enumerate(dataloader):\n",
        "        # Preprocess images\n",
        "        patch_indices = torch.stack([preprocess_image(img) for img in images]).long()\n",
        "        masked_patches = patch_indices.clone()\n",
        "\n",
        "        # Masking\n",
        "        mask = torch.rand(masked_patches.shape) < current_mask_rate\n",
        "        masked_patches[mask] = num_tokens - 1\n",
        "\n",
        "        # Calculate token weights dynamically\n",
        "        token_counts = torch.bincount(patch_indices.view(-1), minlength=num_tokens)\n",
        "        mask_token_count = mask.sum().item()\n",
        "        token_counts[-1] = mask_token_count\n",
        "        token_weights = 1.0 / (token_counts + 1e-6)\n",
        "        token_weights = token_weights / token_weights.sum()\n",
        "        token_weights = token_weights.to(device)\n",
        "\n",
        "        # Define weighted CrossEntropyLoss\n",
        "        criterion = nn.CrossEntropyLoss(weight=token_weights)\n",
        "\n",
        "        # Move to device\n",
        "        masked_patches, patch_indices, mask = (\n",
        "            masked_patches.to(device),\n",
        "            patch_indices.to(device),\n",
        "            mask.to(device),\n",
        "        )\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(masked_patches, mask)\n",
        "        loss = criterion(logits.view(-1, num_tokens), patch_indices.view(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Log batch metrics\n",
        "        wandb.log({\"batch_loss\": loss.item()})\n",
        "\n",
        "        # Visualization for the first batch in the epoch\n",
        "        if batch_idx == 0:\n",
        "            with torch.no_grad():\n",
        "                predicted_indices = torch.argmax(logits, dim=-1).cpu()[0]\n",
        "                reconstructed_image = reconstruct_image_from_patches(predicted_indices)\n",
        "\n",
        "                visualized_masked_patches = masked_patches.cpu()[0].clone()\n",
        "                visualized_masked_patches[visualized_masked_patches == num_tokens - 1] = -1\n",
        "                masked_image = reconstruct_image_from_patches(visualized_masked_patches)\n",
        "\n",
        "                # Log visualizations to wandb\n",
        "                wandb.log({\n",
        "                    \"Original Image\": wandb.Image(\n",
        "                        reconstruct_image_from_patches(patch_indices.cpu()[0])\n",
        "                    ),\n",
        "                    \"Masked Image\": wandb.Image(masked_image, caption=\"Masked Image\"),\n",
        "                    \"Reconstructed Image\": wandb.Image(\n",
        "                        reconstructed_image, caption=\"Reconstructed Image\"\n",
        "                    ),\n",
        "                })\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Log epoch metrics\n",
        "    wandb.log({\"epoch_loss\": avg_loss})\n",
        "\n",
        "# Save the final model\n",
        "torch.save(model.state_dict(), \"vision_transformer_final_balanced.pth\")\n",
        "wandb.save(\"vision_transformer_final_balanced.pth\")\n",
        "print(\"Final model saved as 'vision_transformer_final_balanced.pth'.\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "Miu05semF-YK",
        "outputId": "33405094-0520-4aa0-a929-7518f639c489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx:  0\n",
            "batch:  tensor([[[1., 0., 1., 0.],\n",
            "         [1., 0., 0., 0.],\n",
            "         [1., 1., 0., 1.],\n",
            "         [0., 0., 1., 1.]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b2b95076c0d1>:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(image, dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fL5JfQ6DfU5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}