{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Vision Transfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, feedforward_dim, num_layers, num_tokens, max_patches, dropout=0.0, hidden_dim=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create the embedding matrix for 2-cell binary combinations + 1 mask token\n",
    "        embedding_matrix = torch.zeros((num_tokens, embed_dim))  # Shape: (num_tokens, embed_dim)\n",
    "\n",
    "        # Generate all possible 2-cell binary patches\n",
    "        patches = torch.tensor([\n",
    "            [a, b]\n",
    "            for a in range(2)\n",
    "            for b in range(2)\n",
    "        ])  # Shape: (4, 2) for 4 combinations of 2-cell binary patches\n",
    "\n",
    "        # Assign each patch's values as its embedding\n",
    "        for i, patch in enumerate(patches):\n",
    "            embedding_matrix[i, :] = patch  # Set the embedding to the patch values\n",
    "\n",
    "        # Set the last row to all 2s for the masked token\n",
    "        embedding_matrix[-1, :] = 0.5  # Mask token embedding\n",
    "\n",
    "        # Create embedding layer\n",
    "        self.embedding_matrix = nn.Embedding.from_pretrained(\n",
    "            embedding_matrix, freeze=True\n",
    "        )\n",
    "\n",
    "        # Transformer encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(hidden_dim, num_heads, feedforward_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Load hidden_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Linear layer to project input embeddings\n",
    "        self.input_proj = nn.Linear(embed_dim, self.hidden_dim)\n",
    "        \n",
    "        # Positional embeddings\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(max_patches, 1, self.hidden_dim))  # Shape: (seq_len, 1, hidden_dim)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(self.hidden_dim, num_tokens-1)\n",
    "\n",
    "    def forward(self, patches):\n",
    "        # Retrieve embeddings\n",
    "        embeddings = self.embedding_matrix(patches)  # (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        # Prepare input for transformer layers\n",
    "        x = embeddings.permute(1, 0, 2)  # (seq_len, batch_size, embed_dim)\n",
    "\n",
    "        # Extract seq_len and batch_size\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "        \n",
    "        # Project input to hidden_dim\n",
    "        z = self.input_proj(x)  # Shape: (seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Add positional embedding\n",
    "        pos_emb = self.positional_embedding[:seq_len, :, :].expand(-1, batch_size, -1)  # Shape: (seq_len, batch_size, hidden_dim)\n",
    "        z = z + pos_emb\n",
    "\n",
    "        # Pass through transformer layers\n",
    "        for layer in self.encoder_layers:\n",
    "            z = layer(z)\n",
    "\n",
    "        # Output logits\n",
    "        z = z.permute(1, 0, 2)  # Back to (batch_size, seq_len, hidden_dim)\n",
    "        logits = self.fc_out(z)  # (batch_size, seq_len, num_tokens-1)\n",
    "        return logits\n",
    "\n",
    "    def get_probabilities(self, logits):\n",
    "        \"\"\"Compute probabilities using softmax.\"\"\"\n",
    "        return torch.softmax(logits, dim=-1)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, feedforward_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Ensure hidden_dim is divisible by num_heads\n",
    "        assert self.hidden_dim % self.num_heads == 0, \"Hidden dimension must be divisible by the number of heads.\"\n",
    "\n",
    "        # Multi-head attention\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=self.hidden_dim, num_heads=num_heads, dropout=dropout)\n",
    "\n",
    "        # Feedforward network\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, feedforward_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feedforward_dim, self.hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(self.hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(self.hidden_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z: Tensor of shape (seq_len, batch_size, hidden_dim)\n",
    "        Returns:\n",
    "            Tensor of shape (seq_len, batch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        seq_len, batch_size, hidden_dim = z.size()\n",
    "\n",
    "        # Apply LayerNorm\n",
    "        z_norm = self.norm1(z)\n",
    "\n",
    "        # Self-attention\n",
    "        attn_output, _ = self.attention(z_norm, z_norm, z_norm)  # Shape: (seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Residual connection\n",
    "        z = z + self.dropout(attn_output)\n",
    "\n",
    "        # Feedforward layer\n",
    "        z_norm = self.norm2(z)\n",
    "        feedforward_output = self.feedforward(z_norm)\n",
    "\n",
    "        # Final residual connection\n",
    "        z = z + self.dropout(feedforward_output)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Toy Dataset: 100 Binary 4x4 Images\n",
    "images = torch.randint(0, 2, (100, 4, 4)).long()\n",
    "\n",
    "# Plot the first 10 images in a 5x2 subplot\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 4))\n",
    "fig.suptitle(\"10 First Realizations of Dataset\", fontsize=16)\n",
    "\n",
    "for idx, ax in enumerate(axs.flat):  # Flatten the 2D array of axes for easy iteration\n",
    "    ax.imshow(images[idx].numpy(), cmap=\"gray\")\n",
    "    ax.set_title(f\"Image {idx + 1}\")\n",
    "    ax.axis(\"off\")  # Turn off the axes for cleaner visualization\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make everything ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# Parameters\n",
    "batch_size = 1\n",
    "embed_dim = 2\n",
    "hidden_dim = 3\n",
    "num_heads = 1\n",
    "feedforward_dim = hidden_dim*2  # (2-4)\n",
    "num_layers = 1\n",
    "num_tokens = 5  # 4 tokens + 1 mask token\n",
    "max_patches = 8\n",
    "dropout = 0.2\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "    project=\"vision-transformer-toy-example\",\n",
    "    config={\n",
    "        \"batch_size\": batch_size,\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"feedforward_dim\": feedforward_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"num_tokens\": num_tokens,\n",
    "        \"max_patches\": max_patches,\n",
    "        \"dropout\": dropout,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_epochs\": num_epochs,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model\n",
    "model = VisionTransformer(embed_dim, num_heads, feedforward_dim, num_layers, num_tokens, max_patches, dropout, hidden_dim).to(device)\n",
    "#model.load_state_dict(checkpoint)  # Load model weights\n",
    "# Optimizer and Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Dataloader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "class BinaryImageDataset(Dataset):\n",
    "    def __init__(self, images):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor): Tensor of shape (num_images, 64, 64) with binary values (0 or 1).\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        return torch.tensor(image, dtype=torch.float32)\n",
    "    \n",
    "dataset = BinaryImageDataset(images)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training loop with all the visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Determine the number of patches to mask for this epoch using the scheduler\n",
    "    num_masked_patches = 4\n",
    "\n",
    "    for batch_idx, images in enumerate(dataloader):\n",
    "        # Preprocess images\n",
    "        patch_indices = torch.stack([preprocess_image(img) for img in images]).long()\n",
    "        masked_patches = patch_indices.clone()\n",
    "\n",
    "        # Create a mask for the determined number of patches\n",
    "        mask = torch.zeros_like(masked_patches, dtype=torch.bool, device=device)\n",
    "        for b in range(masked_patches.size(0)):  # Iterate over the batch\n",
    "            mask_indices = torch.randperm(masked_patches.size(1))[:num_masked_patches]\n",
    "            mask[b, mask_indices] = True\n",
    "\n",
    "        # Apply the mask\n",
    "        masked_patches[mask] = num_tokens - 1  # Assign mask token\n",
    "\n",
    "        # Move to device\n",
    "        masked_patches, patch_indices = masked_patches.to(device), patch_indices.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(masked_patches)\n",
    "        \n",
    "        # Take out only the masked patches\n",
    "        masked_logits = torch.stack([logits[i, mask[i], :] for i in range(mask.shape[0])], dim=0)  # (current_batch_size, num_masked, num_tokens-1)\n",
    "        masked_patch_indices = torch.stack([patch_indices[i, mask[i]] for i in range(mask.shape[0])], dim=0)  # (current_batch_size, num_masked)\n",
    "        # Flatten masked logits and masked patch indices\n",
    "        masked_logits = masked_logits.view(-1, num_tokens-1)  # Shape: (batch_size * num_masked, num_tokens-1)\n",
    "        masked_patch_indices = masked_patch_indices.view(-1)  # Shape: (batch_size * num_masked)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(masked_logits,masked_patch_indices)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Log batch metrics\n",
    "        wandb.log({\"batch_loss\": loss.item(), \"num_masked_patches\": num_masked_patches})\n",
    "\n",
    "        # Log visualizations for the first batch\n",
    "        if batch_idx == 0:\n",
    "            with torch.no_grad():\n",
    "                predicted_indices = torch.argmax(logits, dim=-1).cpu()[0]\n",
    "                reconstructed_image = reconstruct_image_from_patches(predicted_indices)\n",
    "\n",
    "                visualized_masked_patches = masked_patches.cpu()[0].clone()\n",
    "                visualized_masked_patches[visualized_masked_patches == num_tokens - 1] = -1\n",
    "                masked_image = reconstruct_image_from_patches(visualized_masked_patches)\n",
    "\n",
    "                wandb.log({\n",
    "                    \"Original Image\": wandb.Image(\n",
    "                        reconstruct_image_from_patches(patch_indices.cpu()[0])\n",
    "                    ),\n",
    "                    \"Masked Image\": wandb.Image(masked_image, caption=\"Masked Image\"),\n",
    "                    \"Reconstructed Image\": wandb.Image(\n",
    "                        reconstructed_image, caption=\"Reconstructed Image\"\n",
    "                    ),\n",
    "                })\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Log epoch metrics\n",
    "    wandb.log({\"epoch_loss\": avg_loss})\n",
    "\n",
    "    # Save model checkpoints every 50 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = f\"checkpoints/vision_transformer_epoch_{epoch+1}.pth\"\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)  # Ensure the directory exists\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved for epoch {epoch+1}\")\n",
    "        wandb.save(checkpoint_path)\n",
    "\n",
    "# Save the final model\n",
    "torch.save(model.state_dict(), \"vision_transformer_final.pth\")\n",
    "wandb.save(\"vision_transformer_final.pth\")\n",
    "print(\"Final model saved as 'vision_transformer_final.pth'.\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a 4x4 - test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.tensor([[0,1,0,1],[1,1,1,1],[1,0,0,0],[0,0,0,0]],dtype=torch.float32)\n",
    "plt.imshow(image,cmap=\"gray\")\n",
    "plt.title(\"Original Image Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Build a masked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask half the patches\n",
    "masked_image = image.clone()\n",
    "masked_image[0,0:2] = 0.5\n",
    "masked_image[1,2:4] = 0.5\n",
    "masked_image[2,2:4] = 0.5\n",
    "masked_image[3,0:2] = 0.5\n",
    "plt.imshow(masked_image,cmap=\"gray\")\n",
    "plt.title(\"Masked Image X\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dimensions\n",
    "masked_patches = torch.zeros(1,8,2) # (batch_size,num_patches,embed_dim)\n",
    "for i in range(8):\n",
    "    if i%2 == 0:\n",
    "        masked_patches[0,i,:] = masked_image[int(i/2),0:2]\n",
    "    else:\n",
    "        masked_patches[0,i,:] = masked_image[int((i-1)/2),2:4]\n",
    "print(\"masked patches: \", masked_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy for easier plotting\n",
    "vectors = masked_patches.squeeze(0).detach().numpy()\n",
    "\n",
    "# Separate the x and y components (embedding dimensions)\n",
    "x_components = vectors[:, 0]  # 1st embedding dimension\n",
    "y_components = vectors[:, 1]  # 2nd embedding dimension\n",
    "\n",
    "# Ensure no LaTeX is used\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(len(vectors)):\n",
    "    # Draw the arrow\n",
    "    plt.arrow(0, 0, x_components[i], y_components[i], \n",
    "              head_width=0.05, head_length=0.1, fc='blue', ec='blue')\n",
    "\n",
    "    # Add plain text label above the arrow\n",
    "    label = f\"x_{i+1}\"  # Simple plain text label\n",
    "    plt.text(x_components[i] + 0.02, y_components[i] + 0.02, label, fontsize=12, color=\"red\")\n",
    "\n",
    "# Add labels and grid\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
    "plt.title(\"Vector embeddings\")\n",
    "plt.xlabel(\"1st Embedding Dimension\")\n",
    "plt.ylabel(\"2nd Embedding Dimension\")\n",
    "\n",
    "# Set axis limits for better visualization\n",
    "plt.xlim(min(x_components)-0.01, max(x_components)+0.1)\n",
    "plt.ylim(min(y_components)-0.01, max(y_components)+0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: build Z = XA^T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a linear layer\n",
    "x = masked_patches.permute(1, 0, 2)  # (num_patches, batch_size, embed_dim)\n",
    "print(\"x: \", x)\n",
    "lin_layer = nn.Linear(2,3)\n",
    "z = lin_layer(x) # (num_patches,batch_size,hidden_dim)\n",
    "print(\"z: \", z)\n",
    "print(\"z dim:\", z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Z vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Reshape to [8, 3] for easier manipulation\n",
    "vectors = z.squeeze(1).detach().numpy()\n",
    "\n",
    "# Normalize the vectors for consistent lengths\n",
    "normalized_vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Extract components for normalized vectors\n",
    "x_components = normalized_vectors[:, 0]  # X components\n",
    "y_components = normalized_vectors[:, 1]  # Y components\n",
    "z_components = normalized_vectors[:, 2]  # Z components\n",
    "\n",
    "# Create the plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add vectors to the plot\n",
    "for i in range(len(normalized_vectors)):\n",
    "    # Start and end points for the vector\n",
    "    x_start, y_start, z_start = 0, 0, 0  # Origin\n",
    "    x_end, y_end, z_end = x_components[i], y_components[i], z_components[i]\n",
    "\n",
    "    # Add the arrow (line)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_start, x_end],\n",
    "        y=[y_start, y_end],\n",
    "        z=[z_start, z_end],\n",
    "        mode=\"lines+markers\",\n",
    "        line=dict(color=\"blue\", width=4),\n",
    "        marker=dict(size=4),\n",
    "        name=f\"z_{i+1}\"\n",
    "    ))\n",
    "\n",
    "    # Add label for the vector\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_end],\n",
    "        y=[y_end],\n",
    "        z=[z_end],\n",
    "        mode=\"text\",\n",
    "        text=[f\"z_{i+1}\"],\n",
    "        textposition=\"top center\",\n",
    "        textfont=dict(size=12, color=\"red\")\n",
    "    ))\n",
    "\n",
    "# Update layout for better aesthetics\n",
    "fig.update_layout(\n",
    "    title=\"3D Vector Embeddings\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"1st Hidden Dim\",\n",
    "        yaxis_title=\"2nd Hidden Dim\",\n",
    "        zaxis_title=\"3rd Hidden Dim\",\n",
    "        xaxis=dict(range=[-1.5, 1.5]),\n",
    "        yaxis=dict(range=[-1.5, 1.5]),\n",
    "        zaxis=dict(range=[-1.5, 1.5])\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Add a Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embedding = nn.Parameter(torch.randn(8, 1, 3))  # Shape: (num_patches, 1, hidden_dim)\n",
    "z = z + positional_embedding\n",
    "print(\"z + positional embedding: \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize with the Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to [8, 3] for easier manipulation\n",
    "vectors = z.squeeze(1).detach().numpy()\n",
    "\n",
    "# Normalize the vectors for consistent lengths\n",
    "normalized_vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Extract components for normalized vectors\n",
    "x_components = normalized_vectors[:, 0]  # X components\n",
    "y_components = normalized_vectors[:, 1]  # Y components\n",
    "z_components = normalized_vectors[:, 2]  # Z components\n",
    "\n",
    "# Create the plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add vectors to the plot\n",
    "for i in range(len(normalized_vectors)):\n",
    "    # Start and end points for the vector\n",
    "    x_start, y_start, z_start = 0, 0, 0  # Origin\n",
    "    x_end, y_end, z_end = x_components[i], y_components[i], z_components[i]\n",
    "\n",
    "    # Add the arrow (line)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_start, x_end],\n",
    "        y=[y_start, y_end],\n",
    "        z=[z_start, z_end],\n",
    "        mode=\"lines+markers\",\n",
    "        line=dict(color=\"blue\", width=4),\n",
    "        marker=dict(size=4),\n",
    "        name=f\"z_{i+1}\"\n",
    "    ))\n",
    "\n",
    "    # Add label for the vector\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_end],\n",
    "        y=[y_end],\n",
    "        z=[z_end],\n",
    "        mode=\"text\",\n",
    "        text=[f\"z_{i+1}\"],\n",
    "        textposition=\"top center\",\n",
    "        textfont=dict(size=12, color=\"red\")\n",
    "    ))\n",
    "\n",
    "# Update layout for better aesthetics\n",
    "fig.update_layout(\n",
    "    title=\"3D Vector embeddings + Positional Embeddings\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"1st Hidden Dim\",\n",
    "        yaxis_title=\"2nd Hidden Dim\",\n",
    "        zaxis_title=\"3rd Hidden Dim\",\n",
    "        xaxis=dict(range=[-1.5, 1.5]),\n",
    "        yaxis=dict(range=[-1.5, 1.5]),\n",
    "        zaxis=dict(range=[-1.5, 1.5])\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Get the attention output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len, batch_size, hidden_dim = z.size()\n",
    "\n",
    "# Apply LayerNorm\n",
    "lay_norm = nn.LayerNorm(3)\n",
    "z_norm = lay_norm(z)\n",
    "\n",
    "attention = nn.MultiheadAttention(embed_dim=3, num_heads=1, dropout=0.0)\n",
    "# Self-attention\n",
    "attn_output, attn_weights = attention(z_norm, z_norm, z_norm)  # Shape: (num_patches, batch_size, hidden_dim)\n",
    "print(\"size of context vector: \", attn_output.size())\n",
    "print(\"size of QK^T-matrix: \", attn_weights.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example tensor of size (1, 8, 8)\n",
    "tensor = attn_weights\n",
    "\n",
    "# Extract the 2D matrix\n",
    "matrix = tensor.squeeze(0).detach().numpy()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(matrix, cmap=\"viridis\", interpolation=\"nearest\")  # Use a colormap\n",
    "plt.colorbar(label=\"Value\")  # Add a color scale\n",
    "\n",
    "# Annotate the values on the heatmap\n",
    "for i in range(matrix.shape[0]):  # Loop over rows\n",
    "    for j in range(matrix.shape[1]):  # Loop over columns\n",
    "        plt.text(j, i, f\"{matrix[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"white\" if matrix[i, j] < 0.5 else \"black\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Attention Scores\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Rows\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Context Vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to [8, 3] for easier manipulation\n",
    "vectors = attn_output.squeeze(1).detach().numpy()\n",
    "\n",
    "# Normalize the vectors for consistent lengths\n",
    "normalized_vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Extract components for normalized vectors\n",
    "x_components = normalized_vectors[:, 0]  # X components\n",
    "y_components = normalized_vectors[:, 1]  # Y components\n",
    "z_components = normalized_vectors[:, 2]  # Z components\n",
    "\n",
    "# Create the plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add vectors to the plot\n",
    "for i in range(len(normalized_vectors)):\n",
    "    # Start and end points for the vector\n",
    "    x_start, y_start, z_start = 0, 0, 0  # Origin\n",
    "    x_end, y_end, z_end = x_components[i], y_components[i], z_components[i]\n",
    "\n",
    "    # Add the arrow (line)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_start, x_end],\n",
    "        y=[y_start, y_end],\n",
    "        z=[z_start, z_end],\n",
    "        mode=\"lines+markers\",\n",
    "        line=dict(color=\"blue\", width=4),\n",
    "        marker=dict(size=4),\n",
    "        name=f\"z_{i+1}\"\n",
    "    ))\n",
    "\n",
    "    # Add label for the vector\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_end],\n",
    "        y=[y_end],\n",
    "        z=[z_end],\n",
    "        mode=\"text\",\n",
    "        text=[f\"c_{i+1}\"],\n",
    "        textposition=\"top center\",\n",
    "        textfont=dict(size=12, color=\"red\")\n",
    "    ))\n",
    "\n",
    "# Update layout for better aesthetics\n",
    "fig.update_layout(\n",
    "    title=\"Context Vectors\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"1st Hidden Dim\",\n",
    "        yaxis_title=\"2nd Hidden Dim\",\n",
    "        zaxis_title=\"3rd Hidden Dim\",\n",
    "        xaxis=dict(range=[-1.5, 1.5]),\n",
    "        yaxis=dict(range=[-1.5, 1.5]),\n",
    "        zaxis=dict(range=[-1.5, 1.5])\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: FFN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward layer\n",
    "z = z + attn_output # (num_tokens,batch_size,hidden_dim)\n",
    "z_norm = lay_norm(z) # (num_tokens,batch_size,hidden_dim)\n",
    "# Feedforward network\n",
    "feedforward = nn.Sequential(\n",
    "    nn.Linear(3, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 3)\n",
    ")\n",
    "feedforward_output = feedforward(z_norm) # (num_tokens,batch_size,hidden_dim)\n",
    "\n",
    "# Final residual connection\n",
    "z = z + feedforward_output # (num_tokens,batch_size,hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Extract weights\n",
    "layer1_weights = feedforward[0].weight.detach().numpy()  # Weights of the first linear layer\n",
    "layer2_weights = feedforward[2].weight.detach().numpy()  # Weights of the second linear layer\n",
    "output_values = feedforward_output[0].detach().numpy()  # Select the first row to handle dimensions  # Extract values for output nodes\n",
    "# Prepare text for labels\n",
    "input_weights_text = [f\"{w:.2f}\" for w in layer1_weights.mean(axis=0)]  # Average weights for input layer\n",
    "hidden_weights_text = [f\"{w:.2f}\" for w in layer2_weights.mean(axis=0)]  # Average weights for hidden layer\n",
    "output_weights_text = [f\"{float(v):.2f}\" for v in output_values]  # Explicitly convert to Python float   # Just label the outputs generically\n",
    "\n",
    "# Initialize the graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define layers\n",
    "input_layer = [f\"Input {i+1}\" for i in range(3)]\n",
    "hidden_layer = [f\"Hidden {i+1}\" for i in range(6)]\n",
    "#output_layer = [f\"Output {i+1}\" for i in range(3)]\n",
    "\n",
    "# Add nodes with weights as labels\n",
    "for i, node in enumerate(input_layer):\n",
    "    G.add_node(node, subset=0, weight=input_weights_text[i])\n",
    "for i, node in enumerate(hidden_layer):\n",
    "    G.add_node(node, subset=1, weight=hidden_weights_text[i])\n",
    "for i, node in enumerate(output_layer):\n",
    "    G.add_node(node, subset=2, weight=output_weights_text[i])\n",
    "\n",
    "# Connect layers\n",
    "for i in input_layer:\n",
    "    for h in hidden_layer:\n",
    "        G.add_edge(i, h)\n",
    "for h in hidden_layer:\n",
    "    for o in output_layer:\n",
    "        G.add_edge(h, o)\n",
    "\n",
    "# Create a multipartite layout\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.multipartite_layout(G, subset_key=\"subset\")\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    labels={n: f\"{n}\\n{G.nodes[n]['weight']}\" for n in G.nodes()},  # Add weights to node labels\n",
    "    node_size=2000,\n",
    "    node_color=\"lightblue\",\n",
    "    edge_color=\"gray\",\n",
    "    font_size=8,\n",
    "    font_weight=\"bold\"\n",
    ")\n",
    "\n",
    "plt.title(\"Feedforward Neural Network with Weights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
