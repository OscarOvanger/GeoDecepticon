{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load and install all dependicies"
      ],
      "metadata": {
        "id": "8rJbl7_Cuzg2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQwb7bUT6z3F",
        "outputId": "d997848d-a2f0-46f3-a7a2-b2044d2496b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install matplotlib\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login de83b34df4865f6d73caa690771345a92e44bb2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_-D2zKHK7ro",
        "outputId": "2d8eeaed-0bd2-4a66-8087-c248be2afb0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OscarOvanger/GeoDecepticon.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZXtl1g-7FeE",
        "outputId": "4590a294-0eaf-4011-d56a-143f3def3ccb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GeoDecepticon'...\n",
            "remote: Enumerating objects: 20272, done.\u001b[K\n",
            "remote: Counting objects: 100% (334/334), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 20272 (delta 263), reused 171 (delta 171), pack-reused 19938 (from 5)\u001b[K\n",
            "Receiving objects: 100% (20272/20272), 162.39 MiB | 6.09 MiB/s, done.\n",
            "Resolving deltas: 100% (567/567), done.\n",
            "Updating files: 100% (83/83), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/GeoDecepticon')"
      ],
      "metadata": {
        "id": "u5fsIzjR7GZa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import wandb\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import copy\n",
        "from ViT import *\n",
        "from ViT_sampling import *\n",
        "from training import *\n",
        "#from sampling import *\n",
        "from tqdm import tqdm  # For progress bars\n",
        "import time"
      ],
      "metadata": {
        "id": "SZFtoPVzEsId"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and plot training data"
      ],
      "metadata": {
        "id": "LT8iK4NzEOg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.load(\"Data/Markov_field/training_data_mod.npz\")[\"arr_0\"]\n",
        "training_data = arr[:9000]\n",
        "test_data = arr[9000:]\n",
        "# We reshape it to 60x60 dataset\n",
        "training_data = training_data.reshape(-1, 64, 64)\n",
        "test_data = test_data.reshape(-1, 64, 64)\n",
        "print(training_data.shape)\n",
        "training_data = torch.tensor(training_data,dtype=torch.float32)\n",
        "sanity_check_data = training_data[:10]\n",
        "test_data = torch.tensor(test_data,dtype=torch.float32)\n",
        "#plot the first data\n",
        "plt.imshow(training_data[100],cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ggDcm9hCEXRB",
        "outputId": "58bc6ede-ef8f-4427-da7d-edd153e41fed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9000, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Condition data"
      ],
      "metadata": {
        "id": "W-xEPyocuwAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "condition_indices = np.array([876,3825,2122,2892,1556,2683,3667,1767,483,2351,\n",
        "                                2000,3312,2953,289,2373,2720,872,2713,1206,1341,\n",
        "                                3541,2226,3423,1904,2882,2540,1497,2524,264,1441])\n",
        "condition_values = np.array([0,1,1,1,0,0,1,0,0,1,0,0,0,1,0,1,0,0,1,0,\n",
        "                              1,1,1,0,1,0,1,1,0,1])\n",
        "condition_indices_x = condition_indices // 64\n",
        "condition_indices_y = condition_indices % 64\n",
        "print(condition_indices_x)\n",
        "print(condition_indices_y)\n",
        "plt.imshow(training_data[0],cmap='gray')\n",
        "plt.scatter(condition_indices_y,condition_indices_x,c=condition_values,cmap='viridis')\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "5PDiCt7uEb6q",
        "outputId": "cf5e0c05-832c-45c1-f10f-0d9d398c4ef6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ncondition_indices = np.array([876,3825,2122,2892,1556,2683,3667,1767,483,2351,\\n                                2000,3312,2953,289,2373,2720,872,2713,1206,1341,\\n                                3541,2226,3423,1904,2882,2540,1497,2524,264,1441])\\ncondition_values = np.array([0,1,1,1,0,0,1,0,0,1,0,0,0,1,0,1,0,0,1,0,\\n                              1,1,1,0,1,0,1,1,0,1])\\ncondition_indices_x = condition_indices // 64\\ncondition_indices_y = condition_indices % 64\\nprint(condition_indices_x)\\nprint(condition_indices_y)\\nplt.imshow(training_data[0],cmap='gray')\\nplt.scatter(condition_indices_y,condition_indices_x,c=condition_values,cmap='viridis')\\nplt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "condition_indices_new = np.array([1726,3797,4211,4543,3953,3347,1897,2015,4424,1942,2108,4350,1019,4068,2911])\n",
        "condition_values_new = np.array([0,1,0,1,1,1,0,1,0,1,0,1,1,1,0])\n",
        "condition_indices_x = (condition_indices_new // 80) - 8\n",
        "condition_indices_y = (condition_indices_new % 80) - 8\n",
        "print(condition_indices_x)\n",
        "print(condition_indices_y)\n",
        "cond_data = np.load(\"Data/Markov_field/training_data_mod_cond.npz\")[\"arr_0\"]\n",
        "plt.imshow(cond_data[105],cmap='gray')\n",
        "plt.scatter(condition_indices_y,condition_indices_x,c=condition_values_new,cmap='viridis')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "4s9PpasrfCoC",
        "outputId": "dab48de8-0c40-4aff-ac16-af65890849dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13 39 44 48 41 33 15 17 47 16 18 46  4 42 28]\n",
            "[38 29 43 55 25 59 49  7 16 14 20 22 51 60 23]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "VFaRaXcOu6GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samps = np.load(\"cond_images_combined.npy\")\n",
        "plt.imshow(samps[2],cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H7-xyfJijwTj",
        "outputId": "db4739e8-2301-4c10-fd42-c31c0ed59ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try training for, say, 500 epochs; you can also try mask_rate=1.0 for a stricter overfit test.\n",
        "nr_epochs = 1000\n",
        "batch_size = 100\n",
        "mask_rate = 0.01  # Try also mask_rate = 1.0 to check if the network can memorize given only positional cues.\n",
        "final_mask_rate = 0.99\n",
        "mask_schedule = \"cyclic\"\n",
        "patch_size = 4\n",
        "num_heads = 2\n",
        "num_layers = 2\n",
        "ffn_dim = 256\n",
        "emb_dim = 64\n",
        "learning_rate = 1e-3\n",
        "vocab_cap = 100000\n",
        "\n",
        "# Assume training_data is already defined with shape (N, H, W)\n",
        "N, H, W = training_data.shape\n",
        "\n",
        "# Set parameters.\n",
        "vocab, counts, mask_token = build_vocabulary(training_data, patch_size, cap_size=vocab_cap)\n",
        "patch_dim = patch_size ** 2\n",
        "num_patches = (H // patch_size) ** 2\n",
        "\n",
        "#samps = torch.tensor(samps,dtype=torch.float32)\n",
        "\n",
        "flattened_condition_indices = np.zeros(len(condition_indices_new))\n",
        "for i in range(len(condition_indices_new)):\n",
        "    flattened_condition_indices[i] = condition_indices_x[i] * 64 + condition_indices_y[i]\n",
        "flattened_condition_indices = flattened_condition_indices.astype(int)\n",
        "\n",
        "# Create the model and load weights.\n",
        "PATH = \"Models/BEST_MODEL.pth\"\n",
        "model = StackedContextViT(\n",
        "    vocab=vocab,\n",
        "    mask_token=mask_token,\n",
        "    patch_dim=patch_dim,\n",
        "    num_patches=num_patches,\n",
        "    emb_dim=emb_dim,\n",
        "    num_heads=num_heads,\n",
        "    num_layers=num_layers,\n",
        "    ffn_dim=ffn_dim,\n",
        "    use_pos_emb=False,          # <— must be True to load the old 256×64 buffer\n",
        "    use_rel_bias=True\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))  # remove weights_only if not applicable\n",
        "\"\"\"\n",
        "trained_model = run_training(training_data, nr_epochs, batch_size, mask_rate,\n",
        "                 final_mask_rate, mask_schedule, patch_size, num_heads,\n",
        "                 num_layers, ffn_dim, learning_rate, emb_dim, vocab_cap,pretrained=model,\n",
        "                 use_pos_emb=False,use_rel_bias=True,rel_bias=model.rel_bias_table)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "EfGJ0p0IXgRr",
        "outputId": "86e8a515-d5a8-4569-b725-30ddee1c64c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrained_model = run_training(training_data, nr_epochs, batch_size, mask_rate, \\n                 final_mask_rate, mask_schedule, patch_size, num_heads, \\n                 num_layers, ffn_dim, learning_rate, emb_dim, vocab_cap,pretrained=model, \\n                 use_pos_emb=False,use_rel_bias=True,rel_bias=model.rel_bias_table)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "O-YZEENA4Zzu",
        "outputId": "94eac352-fc35-4aeb-f95b-4e968a038e11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackedContextViT(\n",
              "  (patch_proj): Linear(in_features=16, out_features=64, bias=True)\n",
              "  (out_drop): Dropout(p=0.1, inplace=False)\n",
              "  (layers): ModuleList(\n",
              "    (0-1): 2 x TransformerEncoderBlock(\n",
              "      (attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
              "      )\n",
              "      (drop1): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): Sequential(\n",
              "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.1, inplace=False)\n",
              "        (3): Linear(in_features=256, out_features=64, bias=True)\n",
              "        (4): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (out_proj): Linear(in_features=64, out_features=5485, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "ckpt_path = \"Models/BEST_MODEL.pth\"\n",
        "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "\n",
        "print(\"=== CHECKPOINT PARAMS ===\")\n",
        "for k, v in ckpt.items():\n",
        "    # some entries in a checkpoint might be nested dicts (e.g. optimizer states)\n",
        "    # we only want the tensors, so check isinstance(v, torch.Tensor)\n",
        "    if isinstance(v, torch.Tensor):\n",
        "        print(f\"{k:40s}  {tuple(v.shape)}  dtype={v.dtype}\")\n",
        "    else:\n",
        "        print(f\"{k:40s}  (type={type(v)})\")"
      ],
      "metadata": {
        "id": "qwQ77wR92dFk",
        "outputId": "caa05bdb-3375-4e49-990d-36f9f9cbeef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKPOINT PARAMS ===\n",
            "mask_token                                (16,)  dtype=torch.float32\n",
            "rel_bias_table                            (31, 31)  dtype=torch.float32\n",
            "pos_emb                                   (1,)  dtype=torch.float32\n",
            "patch_proj.weight                         (64, 16)  dtype=torch.float32\n",
            "patch_proj.bias                           (64,)  dtype=torch.float32\n",
            "layers.0.attn.in_proj_weight              (192, 64)  dtype=torch.float32\n",
            "layers.0.attn.in_proj_bias                (192,)  dtype=torch.float32\n",
            "layers.0.attn.out_proj.weight             (64, 64)  dtype=torch.float32\n",
            "layers.0.attn.out_proj.bias               (64,)  dtype=torch.float32\n",
            "layers.0.norm1.weight                     (64,)  dtype=torch.float32\n",
            "layers.0.norm1.bias                       (64,)  dtype=torch.float32\n",
            "layers.0.ffn.0.weight                     (256, 64)  dtype=torch.float32\n",
            "layers.0.ffn.0.bias                       (256,)  dtype=torch.float32\n",
            "layers.0.ffn.3.weight                     (64, 256)  dtype=torch.float32\n",
            "layers.0.ffn.3.bias                       (64,)  dtype=torch.float32\n",
            "layers.0.norm2.weight                     (64,)  dtype=torch.float32\n",
            "layers.0.norm2.bias                       (64,)  dtype=torch.float32\n",
            "layers.1.attn.in_proj_weight              (192, 64)  dtype=torch.float32\n",
            "layers.1.attn.in_proj_bias                (192,)  dtype=torch.float32\n",
            "layers.1.attn.out_proj.weight             (64, 64)  dtype=torch.float32\n",
            "layers.1.attn.out_proj.bias               (64,)  dtype=torch.float32\n",
            "layers.1.norm1.weight                     (64,)  dtype=torch.float32\n",
            "layers.1.norm1.bias                       (64,)  dtype=torch.float32\n",
            "layers.1.ffn.0.weight                     (256, 64)  dtype=torch.float32\n",
            "layers.1.ffn.0.bias                       (256,)  dtype=torch.float32\n",
            "layers.1.ffn.3.weight                     (64, 256)  dtype=torch.float32\n",
            "layers.1.ffn.3.bias                       (64,)  dtype=torch.float32\n",
            "layers.1.norm2.weight                     (64,)  dtype=torch.float32\n",
            "layers.1.norm2.bias                       (64,)  dtype=torch.float32\n",
            "out_proj.weight                           (5485, 64)  dtype=torch.float32\n",
            "out_proj.bias                             (5485,)  dtype=torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume training_data is already defined with shape (N, H, W)\n",
        "N, H, W = training_data.shape\n",
        "\n",
        "# Set parameters.\n",
        "vocab, counts, mask_token = build_vocabulary(training_data, patch_size, cap_size=vocab_cap)\n",
        "patch_dim = patch_size ** 2\n",
        "num_patches = (H // patch_size) ** 2\n",
        "\n",
        "#samps = torch.tensor(samps,dtype=torch.float32)\n",
        "\n",
        "flattened_condition_indices = np.zeros(len(condition_indices_new))\n",
        "for i in range(len(condition_indices_new)):\n",
        "    flattened_condition_indices[i] = condition_indices_x[i] * 64 + condition_indices_y[i]\n",
        "flattened_condition_indices = flattened_condition_indices.astype(int)\n",
        "\n",
        "# Create the model and load weights.\n",
        "PATH = \"Models/BEST_MODEL.pth\"\n",
        "model = StackedContextViT(\n",
        "    vocab=vocab,\n",
        "    mask_token=mask_token,\n",
        "    patch_dim=patch_dim,\n",
        "    num_patches=num_patches,\n",
        "    emb_dim=emb_dim,\n",
        "    num_heads=num_heads,\n",
        "    num_layers=num_layers,\n",
        "    ffn_dim=ffn_dim,\n",
        "    use_pos_emb=False,          # <— must be True to load the old 256×64 buffer\n",
        "    use_rel_bias=True\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))  # remove weights_only if not applicable\n",
        "\"\"\"\n",
        "model.to(device)\n",
        "model.vocab = model.vocab.to(device)\n",
        "model.mask_token = model.mask_token.to(device)\n",
        "images,ll = generate_images_batch(model, patch_size, image_size=H, batch_size=3,device=device,\n",
        "                          condition_indices=flattened_condition_indices, condition_values=condition_values_new,\n",
        "                          generation_order=\"manhattan\")\n",
        "plt.imshow(images[0],cmap='gray')\n",
        "plt.title(f\"ll: {ll[0]}\")\n",
        "plt.show()\n",
        "images = images.to(device)\n",
        "ll_new = log_likelihood_evaluation_batch(\n",
        "    model,\n",
        "    images,            # tensor [B, H, W] of binary images\n",
        "    patch_size,              # int\n",
        "    condition_indices=flattened_condition_indices,\n",
        "    condition_values=condition_values_new,\n",
        "    generation_order=\"manhattan\"\n",
        ")\n",
        "print(f\"ll_new: {ll_new[0]}\")\n",
        "samps = samps.to(device)\n",
        "ll_VEA_full = []\n",
        "for i in range(30):\n",
        "  ll_VEA = log_likelihood_evaluation_batch(\n",
        "      model,\n",
        "      samps[i*100:(i+1)*100],            # tensor [B, H, W] of binary images\n",
        "      patch_size,              # int\n",
        "      condition_indices=flattened_condition_indices,\n",
        "      condition_values=condition_values_new,\n",
        "      generation_order=\"manhattan\"\n",
        "  )\n",
        "  ll_VEA_full.append(ll_VEA)\n",
        "print(ll_VEA)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "q7BhKWY0shM0",
        "outputId": "68a93e51-afa1-4301-cbf4-bdde186aefe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'patch_size' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-488f78340e38>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Set parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_cap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_size\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'patch_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_log_likelihood_batch(\n",
        "    model,\n",
        "    device,\n",
        "    image_batches,\n",
        "    condition_indices=None,\n",
        "    condition_values=None,\n",
        "    generation_order=\"manhattan\",\n",
        "    atol=1e-6\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute sum of log-likelihoods for a batch of fully-observed images under\n",
        "    the masked‐patch sequential model, following the specified generation_order.\n",
        "\n",
        "    Args:\n",
        "        model:            PyTorch model with attributes\n",
        "                          - .vocab       (Tensor[V, D])\n",
        "                          - .mask_token  (Tensor[D])\n",
        "                          and callable forward(inputs, mask_rate=0.0) -> (logits, _)\n",
        "        device:           torch device (e.g. \"cuda\")\n",
        "        image_batches:    FloatTensor of shape [B, H, W], values in [0,1]\n",
        "        condition_indices: List of flattened pixel indices to treat as\n",
        "                           additional observed constraints (shared across batch)\n",
        "        condition_values:  List of 0/1 values for those indices\n",
        "        generation_order:  One of \"raster\", \"manhattan\", \"inverse manhattan\"\n",
        "        atol:             Tolerance for matching patch vectors to vocab\n",
        "\n",
        "    Returns:\n",
        "        log_likelihoods:  FloatTensor of shape [B], sum of per-patch log-probs\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    image_batches = image_batches.to(device)\n",
        "    B, H, W = image_batches.shape\n",
        "    # infer patch size & grid\n",
        "    D = model.mask_token.shape[0]\n",
        "    P = int(math.sqrt(D))\n",
        "    assert P*P == D, \"mask_token dim not a square\"\n",
        "    assert H == W and H % P == 0, \"image size must be divisible by patch_size\"\n",
        "    G = H // P\n",
        "    T = G * G\n",
        "\n",
        "    # pull out true patch vectors: [B, T, D]\n",
        "    patches = (\n",
        "        image_batches\n",
        "        .unfold(1, P, P)          # -> [B, G, W, P]\n",
        "        .unfold(2, P, P)          # -> [B, G, G, P, P]\n",
        "        .permute(0,1,2,3,4)       # ensure layout\n",
        "        .contiguous()\n",
        "        .view(B, T, D)\n",
        "    )\n",
        "\n",
        "    # build patch-level condition map\n",
        "    conditions_by_patch = {}\n",
        "    if condition_indices is not None and condition_values is not None:\n",
        "        for pix_idx, pix_val in zip(condition_indices, condition_values):\n",
        "            pr, pc = divmod(pix_idx, H)\n",
        "            pr0, pc0 = pr // P, pc // P\n",
        "            pidx = pr0 * G + pc0\n",
        "            local = (pr % P)*P + (pc % P)\n",
        "            conditions_by_patch.setdefault(pidx, []).append((local, pix_val))\n",
        "\n",
        "    # figure out sampling order\n",
        "    observed = sorted(conditions_by_patch.keys())\n",
        "    all_p   = set(range(T))\n",
        "    unobs   = list(all_p - set(observed))\n",
        "\n",
        "    if generation_order == \"raster\":\n",
        "        unobs.sort()\n",
        "    elif generation_order == \"manhattan\":\n",
        "        if observed:\n",
        "            dist = []\n",
        "            for p in unobs:\n",
        "                r,c = divmod(p, G)\n",
        "                s = sum(abs(r - (o//G)) + abs(c - (o%G)) for o in observed)\n",
        "                dist.append((p,s))\n",
        "            unobs = [p for p,_ in sorted(dist, key=lambda x: x[1])]\n",
        "        else:\n",
        "            unobs.sort()\n",
        "    elif generation_order == \"inverse manhattan\":\n",
        "        if observed:\n",
        "            inv = []\n",
        "            for p in unobs:\n",
        "                r,c = divmod(p, G)\n",
        "                s = sum(1.0/(abs(r-(o//G))+abs(c-(o%G))) for o in observed)\n",
        "                inv.append((p,s))\n",
        "            unobs = [p for p,_ in sorted(inv, key=lambda x: x[1], reverse=True)]\n",
        "        else:\n",
        "            unobs.sort()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown generation_order {generation_order}\")\n",
        "\n",
        "    sampling_order = observed + unobs\n",
        "\n",
        "    # prepare storage\n",
        "    log_likes = torch.zeros(B, device=device)\n",
        "    mask_tok  = model.mask_token.detach().to(device)      # [D]\n",
        "    vocab     = model.vocab.to(device)                    # [V, D]\n",
        "    V         = vocab.shape[0]\n",
        "\n",
        "    # initially mask all patches\n",
        "    generated = mask_tok.unsqueeze(0).unsqueeze(0)\\\n",
        "                   .expand(B, T, D).clone()\n",
        "\n",
        "    # sequentially fill in actual patches, accumulating log‐probs\n",
        "    for p in sampling_order:\n",
        "        with torch.no_grad():\n",
        "            logits_full, _ = model(generated.to(device), mask_rate=0.0)\n",
        "        # logits for this patch: [B, V]\n",
        "        logits_p = logits_full[:, p, :]\n",
        "\n",
        "        # apply any patch‐level condition constraints\n",
        "        if p in conditions_by_patch:\n",
        "            valid = torch.ones(V, dtype=torch.bool, device=device)\n",
        "            for local_i, val in conditions_by_patch[p]:\n",
        "                valid &= (vocab[:, local_i] == val)\n",
        "            logits_p = logits_p.masked_fill(~valid.unsqueeze(0), -float('inf'))\n",
        "\n",
        "        # compute probabilities\n",
        "        probs_p = F.softmax(logits_p, dim=-1)  # [B, V]\n",
        "\n",
        "        # find the true token index for each image in batch\n",
        "        # compare vocab rows to the true patch vector\n",
        "        # -> [B, V, D] difference, then match along D\n",
        "        diff    = vocab.unsqueeze(0) - patches[:, p, :].unsqueeze(1)  # [B, V, D]\n",
        "        matches = torch.all(torch.abs(diff) < atol, dim=2)           # [B, V]\n",
        "        # argmax gives first True index (we assume every patch is in vocab)\n",
        "        true_idx = matches.float().argmax(dim=1)                      # [B]\n",
        "\n",
        "        # gather the probability assigned to the true token, accumulate\n",
        "        p_true = probs_p[torch.arange(B, device=device), true_idx]\n",
        "        log_likes += torch.log(p_true + 1e-10)\n",
        "\n",
        "        # now “fill in” that patch with the true vocab vector\n",
        "        generated[:, p, :] = vocab[true_idx]\n",
        "\n",
        "    return log_likes"
      ],
      "metadata": {
        "id": "MZoh8Xq3Um5o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.load(\"Data/Markov_field/training_data_mod_cond.npz\")[\"arr_0\"]\n",
        "manhattan_img = np.load('cond_images_manhattan (3).npy')\n",
        "inv_manhattan_img = np.load('reverse_manhattan_images.npy')\n",
        "manhattan_img_temp = np.load('manhattan_images.npy')\n",
        "inv_manhattan_img_temp = np.load('reverse_manhattan_images (1).npy')\n",
        "samps = np.concatenate((arr,manhattan_img,inv_manhattan_img,manhattan_img_temp,inv_manhattan_img_temp))\n",
        "samps = np.array(samps)\n",
        "samps.shape"
      ],
      "metadata": {
        "id": "eM_KRkTMj5dd",
        "outputId": "467b4aa1-7778-47a4-9569-500e64f43ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 64, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_lik_list = []\n",
        "for i in range(500):\n",
        "  curr_batch = samps[i*10:(i+1)*10]\n",
        "  curr_batch = torch.tensor(curr_batch,dtype=torch.float32).to(device)\n",
        "  log_lik = compute_log_likelihood_batch(\n",
        "      model,\n",
        "      device,\n",
        "      curr_batch,\n",
        "      condition_indices=flattened_condition_indices,\n",
        "      condition_values=condition_values_new,\n",
        "      generation_order=\"manhattan\",\n",
        "      atol=1e-6\n",
        "  )\n",
        "  log_lik_list.append(log_lik)\n",
        "  print(f\"sampled {i+1} out of 500\")\n",
        "#print(log_lik_list)\n",
        "# Convert to numpy array\n",
        "log_lik_array = np.array(log_lik_list)\n",
        "# save numpy array\n",
        "np.save(\"log_lik_array_all_samples_manhattan.npy\", log_lik_array)"
      ],
      "metadata": {
        "id": "fC_0qsqZXxqz",
        "outputId": "187d2975-8f3c-4e9a-8a13-1869c5f73bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sampled 1 out of 500\n",
            "sampled 2 out of 500\n",
            "sampled 3 out of 500\n",
            "sampled 4 out of 500\n",
            "sampled 5 out of 500\n",
            "sampled 6 out of 500\n",
            "sampled 7 out of 500\n",
            "sampled 8 out of 500\n",
            "sampled 9 out of 500\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7a30c67e1228>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mcurr_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcurr_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   log_lik = compute_log_likelihood_batch(\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a33625318473>\u001b[0m in \u001b[0;36mcompute_log_likelihood_batch\u001b[0;34m(model, device, image_batches, condition_indices, condition_values, generation_order, atol)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampling_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mlogits_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;31m# logits for this patch: [B, V]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mlogits_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GeoDecepticon/ViT.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, patches, mask_rate)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# 5) apply transformer layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# 6) final logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GeoDecepticon/ViT.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# attn_mask here is [N,N] if provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6369\u001b[0;31m             attn_output_weights = torch.baddbmm(\n\u001b[0m\u001b[1;32m   6370\u001b[0m                 \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6371\u001b[0m             )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.vocab = model.vocab.to(device)\n",
        "model.mask_token = model.mask_token.to(device)\n",
        "reverse_manhattan_images = []\n",
        "reverse_manhattan_lls = []\n",
        "for i in range(10):\n",
        "  images,ll = generate_images_batch(model, patch_size, image_size=H, batch_size=100,device=device,\n",
        "                          condition_indices=flattened_condition_indices, condition_values=condition_values_new,\n",
        "                          generation_order=\"manhattan\",temperature=0.9)\n",
        "  images = images.cpu().detach().numpy()\n",
        "  reverse_manhattan_images.append(images)\n",
        "  reverse_manhattan_lls.append(ll)"
      ],
      "metadata": {
        "id": "QrR6lK1Qld7u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_manhattan_images = np.concatenate(reverse_manhattan_images,axis=0)\n",
        "reverse_manhattan_lls = np.concatenate(reverse_manhattan_lls,axis=0)"
      ],
      "metadata": {
        "id": "HZrjH1pE86kG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"manhattan_images.npy\",reverse_manhattan_images)\n",
        "np.save(\"manhattan_lls.npy\",reverse_manhattan_lls)"
      ],
      "metadata": {
        "id": "6boatnrF92B3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 0) Ensure you have your `patches_to_image` helper in scope:\n",
        "# -------------------------------------------------------------------\n",
        "# def patches_to_image(patches_tensor, image_size, patch_size):\n",
        "#     # your implementation here\n",
        "#     ...\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 1) Hook for capturing real soft‐attention weights\n",
        "# -------------------------------------------------------------------\n",
        "attn_store = []\n",
        "def _attn_hook(module, inp, out):\n",
        "    # out = (attn_output, attn_output_weights)\n",
        "    attn_store.append(out[1].detach())\n",
        "# register on each MultiheadAttention\n",
        "for layer in model.layers:\n",
        "    layer.attn.register_forward_hook(_attn_hook)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 2) Helper functions\n",
        "# -------------------------------------------------------------------\n",
        "def add_colored_border(token, border_width=1, border_color=(1, 0, 0)):\n",
        "    token_rgb = np.stack([token]*3, axis=-1)\n",
        "    H, W, _ = token_rgb.shape\n",
        "    new_H, new_W = H + 2*border_width, W + 2*border_width\n",
        "    bordered = np.ones((new_H, new_W, 3)) * 0.5\n",
        "    bordered[border_width:border_width+H, border_width:border_width+W] = token_rgb\n",
        "    bordered[:border_width, :] = border_color\n",
        "    bordered[-border_width:, :] = border_color\n",
        "    bordered[:, :border_width] = border_color\n",
        "    bordered[:, -border_width:] = border_color\n",
        "    return bordered\n",
        "\n",
        "def fig_to_np(fig):\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "    buf.seek(0)\n",
        "    return np.array(Image.open(buf).convert(\"RGB\"))\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 3) Full generate_video() with temperature parameter\n",
        "# -------------------------------------------------------------------\n",
        "def generate_video(\n",
        "    model,\n",
        "    patch_size,\n",
        "    image_size,\n",
        "    condition_indices=None,\n",
        "    condition_values=None,\n",
        "    topk=10,\n",
        "    temperature=1.0,\n",
        "    video_filename=\"generation_with_attn.mp4\",\n",
        "    fps=4,\n",
        "    generation_order=\"manhattan\",\n",
        "    given_image=None,\n",
        "):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    grid = image_size // patch_size\n",
        "    T = grid * grid\n",
        "    D = patch_size * patch_size\n",
        "    V = model.vocab.size(0)\n",
        "\n",
        "    # scatter coords\n",
        "    if condition_indices is not None:\n",
        "        ys = condition_indices // image_size\n",
        "        xs = condition_indices % image_size\n",
        "\n",
        "    # initialize states\n",
        "    mask_tok  = model.mask_token.detach().to(device)\n",
        "    gen_state = mask_tok.unsqueeze(0).expand(T, D).clone()\n",
        "    gt_state  = mask_tok.unsqueeze(0).expand(T, D).clone()\n",
        "    done      = torch.zeros(T, dtype=torch.bool, device=device)\n",
        "\n",
        "    # ground‐truth patches\n",
        "    if given_image is not None:\n",
        "        gimg = (torch.from_numpy(given_image)\n",
        "                if isinstance(given_image, np.ndarray)\n",
        "                else given_image).to(device)\n",
        "        g_patches = []\n",
        "        for p in range(T):\n",
        "            r0 = (p//grid)*patch_size\n",
        "            c0 = (p%grid)*patch_size\n",
        "            g_patches.append(gimg[r0:r0+patch_size, c0:c0+patch_size].reshape(-1))\n",
        "        g_patches = torch.stack(g_patches)\n",
        "    else:\n",
        "        g_patches = None\n",
        "\n",
        "    # conditions per patch\n",
        "    conditions = {}\n",
        "    if condition_indices is not None and condition_values is not None:\n",
        "        for pix, val in zip(condition_indices, condition_values):\n",
        "            pr, pc = divmod(pix, image_size)\n",
        "            pidx = (pr//patch_size)*grid + (pc//patch_size)\n",
        "            lidx = (pr % patch_size)*patch_size + (pc % patch_size)\n",
        "            conditions.setdefault(pidx, []).append((lidx, val))\n",
        "\n",
        "    # sampling order\n",
        "    observed = sorted(conditions.keys())\n",
        "    unobs    = list(set(range(T)) - set(observed))\n",
        "    if generation_order == \"raster\":\n",
        "        unobs.sort()\n",
        "    elif generation_order == \"manhattan\":\n",
        "        dist = [(p, sum(abs(p//grid - o//grid) + abs(p%grid - o%grid) for o in observed)) for p in unobs]\n",
        "        unobs = [p for p,_ in sorted(dist, key=lambda x: x[1])]\n",
        "    elif generation_order == \"inverse manhattan\":\n",
        "        inv  = [(p, sum(1.0/(abs(p//grid - o//grid) + abs(p%grid - o%grid)) for o in observed)) for p in unobs]\n",
        "        unobs = [p for p,_ in sorted(inv, key=lambda x: x[1], reverse=True)]\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown generation_order {generation_order}\")\n",
        "    order = observed + unobs\n",
        "\n",
        "    # accumulators\n",
        "    acc_ll_gen = acc_ll_gt = 0.0\n",
        "    mode_count_gen = mode_count_gt = 0\n",
        "\n",
        "    frames = []\n",
        "    scatter_cmap = ListedColormap([\"blue\",\"red\"])\n",
        "\n",
        "    for step, pidx in enumerate(tqdm(order, desc=\"Sampling\")):\n",
        "        # 1) capture gen attentions\n",
        "        attn_store.clear()\n",
        "        logits_gen, _ = model(gen_state.unsqueeze(0), mask_rate=0.0)\n",
        "        attn_weights_gen = torch.stack(attn_store, dim=0)[:, 0]  # [layers, T, T]\n",
        "\n",
        "        # 2) capture given attentions\n",
        "        attn_store.clear()\n",
        "        logits_gt, _ = model(gt_state.unsqueeze(0), mask_rate=0.0)\n",
        "        attn_weights_gt = torch.stack(attn_store, dim=0)[:, 0]\n",
        "\n",
        "        # 3) build log‐attention maps\n",
        "        eps = 1e-12\n",
        "        avg_gen = attn_weights_gen.mean(dim=0)[pidx]\n",
        "        norm_gen = avg_gen / avg_gen.sum()\n",
        "        log_gen  = torch.log(norm_gen + eps)\n",
        "        attn_map_gen = log_gen.reshape(grid, grid).cpu().detach().numpy()\n",
        "\n",
        "        avg_gt  = attn_weights_gt.mean(dim=0)[pidx]\n",
        "        norm_gt = avg_gt / avg_gt.sum()\n",
        "        log_gt  = torch.log(norm_gt + eps)\n",
        "        attn_map_gt  = log_gt.reshape(grid, grid).cpu().detach().numpy()\n",
        "\n",
        "        # 4) sample & ll with temperature\n",
        "        # apply temperature only to generated sampling\n",
        "        logits_t = logits_gen[0, pidx] / temperature\n",
        "        probs_gen = F.softmax(logits_t, dim=-1)\n",
        "        probs_gt  = F.softmax(logits_gt[0, pidx],  dim=-1)\n",
        "\n",
        "        if pidx in conditions:\n",
        "            valid = torch.ones(V, dtype=torch.bool, device=device)\n",
        "            for li, val in conditions[pidx]:\n",
        "                valid &= (model.vocab[:, li] == val)\n",
        "            probs_gen = probs_gen.masked_fill(~valid, 0)\n",
        "            probs_gt  = probs_gt.masked_fill(~valid, 0)\n",
        "            probs_gen /= probs_gen.sum()\n",
        "            probs_gt  /= probs_gt.sum()\n",
        "\n",
        "        tok_gen = torch.multinomial(probs_gen, 1).item()\n",
        "        acc_ll_gen += float(torch.log(probs_gen[tok_gen] + 1e-10))\n",
        "        gen_state[pidx] = model.vocab[tok_gen]\n",
        "        if tok_gen == int(torch.argmax(probs_gen)):\n",
        "            mode_count_gen += 1\n",
        "\n",
        "        if g_patches is not None:\n",
        "            dists   = ((model.vocab.to(device) - g_patches[pidx].unsqueeze(0))**2).sum(-1)\n",
        "            idx_gt  = int(torch.argmin(dists))\n",
        "            acc_ll_gt += float(torch.log(probs_gt[idx_gt] + 1e-10))\n",
        "            gt_state[pidx] = model.vocab[idx_gt]\n",
        "            if idx_gt == int(torch.argmax(probs_gt)):\n",
        "                mode_count_gt += 1\n",
        "        else:\n",
        "            idx_gt = None\n",
        "\n",
        "        done[pidx] = True\n",
        "\n",
        "        # topk arrays\n",
        "        topk_inds_gen = torch.topk(probs_gen, topk).indices.cpu().detach().numpy()\n",
        "        topk_vals_gen = probs_gen[topk_inds_gen].cpu().detach().numpy()\n",
        "        topk_inds_gt  = torch.topk(probs_gt, topk).indices.cpu().detach().numpy()\n",
        "        topk_vals_gt  = probs_gt[topk_inds_gt].cpu().detach().numpy()\n",
        "\n",
        "        # 5) plot 2×5 grid\n",
        "        fig, axs = plt.subplots(2, 5, figsize=(40, 16))\n",
        "\n",
        "        # Given Context + scatter\n",
        "        disp_gt = [gt_state[i] if done[i] else torch.full((D,), 0.5, device=device) for i in range(T)]\n",
        "        img_gt  = patches_to_image(torch.stack(disp_gt), (image_size, image_size), patch_size)\n",
        "        axs[0,0].imshow(img_gt.cpu(), cmap=\"gray\", vmin=0, vmax=1)\n",
        "        if condition_indices is not None:\n",
        "            axs[0,0].scatter(xs, ys, c=condition_values, cmap=scatter_cmap, s=20, edgecolors=\"white\")\n",
        "        axs[0,0].add_patch(mpatches.Rectangle(\n",
        "            ((pidx%grid)*patch_size - .5, (pidx//grid)*patch_size - .5),\n",
        "            patch_size, patch_size, linewidth=2, edgecolor=\"green\", facecolor=\"none\"\n",
        "        ))\n",
        "        axs[0,0].set_title(\"Given Context\"); axs[0,0].axis(\"off\")\n",
        "\n",
        "        # Given log‐attention + highlight + colorbar\n",
        "        im0 = axs[0,1].imshow(attn_map_gt, cmap=\"viridis\", vmin=-15, vmax=0)\n",
        "        r, c = divmod(pidx, grid)\n",
        "        axs[0,1].add_patch(mpatches.Rectangle(\n",
        "            (c - .5, r - .5), 1, 1, linewidth=2, edgecolor=\"green\", facecolor=\"none\"\n",
        "        ))\n",
        "        axs[0,1].set_title(\"Given log-Attention\"); axs[0,1].axis(\"off\")\n",
        "        fig.colorbar(im0, ax=axs[0,1], fraction=0.046, pad=0.04)\n",
        "\n",
        "        # P on Given\n",
        "        colors_gt = [\"purple\"]*topk\n",
        "        if idx_gt is not None:\n",
        "            for i, tid in enumerate(topk_inds_gt):\n",
        "                if tid == idx_gt:\n",
        "                    colors_gt[i] = \"orange\"\n",
        "        axs[0,2].bar(np.arange(topk), topk_vals_gt, color=colors_gt)\n",
        "        axs[0,2].set_xticks(np.arange(topk)); axs[0,2].set_xticklabels(topk_inds_gt, fontsize=12)\n",
        "        axs[0,2].set_ylim(0,1); axs[0,2].set_title(\"P on Given\")\n",
        "\n",
        "        # Top-10 Given tokens\n",
        "        giv_tiles = [model.vocab[int(tid)].cpu().reshape(patch_size,patch_size).numpy() for tid in topk_inds_gt]\n",
        "        giv_grid  = np.hstack([add_colored_border(t,1,(1,0.5,0)) for t in giv_tiles])\n",
        "        axs[0,3].imshow(giv_grid, cmap=\"gray\", vmin=0, vmax=1); axs[0,3].axis(\"off\"); axs[0,3].set_title(\"Top-10 Given\")\n",
        "\n",
        "        # Given patch w/ stats\n",
        "        if idx_gt is not None:\n",
        "            arr_gt = model.vocab[idx_gt].cpu().reshape(patch_size,patch_size).numpy()\n",
        "            axs[0,4].imshow(add_colored_border(arr_gt,1,(1,0.5,0)), cmap=\"gray\", vmin=0, vmax=1)\n",
        "            axs[0,4].axis(\"off\")\n",
        "            axs[0,4].set_title(f\"p={probs_gt[idx_gt]:.3f}\\nΣ_ll={acc_ll_gt:.3f}\\nmode_cnt={mode_count_gt}\")\n",
        "        else:\n",
        "            axs[0,4].axis(\"off\")\n",
        "\n",
        "        # Gen Context + scatter\n",
        "        disp_gen = [gen_state[i] if done[i] else torch.full((D,), 0.5, device=device) for i in range(T)]\n",
        "        img_gen  = patches_to_image(torch.stack(disp_gen), (image_size, image_size), patch_size)\n",
        "        axs[1,0].imshow(img_gen.cpu(), cmap=\"gray\", vmin=0, vmax=1)\n",
        "        if condition_indices is not None:\n",
        "            axs[1,0].scatter(xs, ys, c=condition_values, cmap=scatter_cmap, s=20, edgecolors=\"white\")\n",
        "        axs[1,0].add_patch(mpatches.Rectangle(\n",
        "            ((pidx%grid)*patch_size - .5, (pidx//grid)*patch_size - .5),\n",
        "            patch_size, patch_size, linewidth=2, edgecolor=\"green\", facecolor=\"none\"\n",
        "        ))\n",
        "        axs[1,0].set_title(\"Gen Context\"); axs[1,0].axis(\"off\")\n",
        "\n",
        "        # Gen log-attention + highlight + colorbar\n",
        "        im1 = axs[1,1].imshow(attn_map_gen, cmap=\"viridis\", vmin=-15, vmax=0)\n",
        "        axs[1,1].add_patch(mpatches.Rectangle(\n",
        "            (c - .5, r - .5), 1, 1, linewidth=2, edgecolor=\"green\", facecolor=\"none\"\n",
        "        ))\n",
        "        axs[1,1].set_title(\"Gen log-Attention\"); axs[1,1].axis(\"off\")\n",
        "        fig.colorbar(im1, ax=axs[1,1], fraction=0.046, pad=0.04)\n",
        "\n",
        "        # P on Generated\n",
        "        colors_gen = [\"purple\"]*topk\n",
        "        for i, tid in enumerate(topk_inds_gen):\n",
        "            if tid == tok_gen:\n",
        "                colors_gen[i] = \"green\"\n",
        "        axs[1,2].bar(np.arange(topk), topk_vals_gen, color=colors_gen)\n",
        "        axs[1,2].set_xticks(np.arange(topk)); axs[1,2].set_xticklabels(topk_inds_gen, fontsize=12)\n",
        "        axs[1,2].set_ylim(0,1); axs[1,2].set_title(\"P on Generated\")\n",
        "\n",
        "        # Top-10 Gen tokens\n",
        "        samp_tiles = [model.vocab[int(tid)].cpu().reshape(patch_size,patch_size).numpy() for tid in topk_inds_gen]\n",
        "        samp_grid  = np.hstack([add_colored_border(t,1,(0,1,0)) for t in samp_tiles])\n",
        "        axs[1,3].imshow(samp_grid, cmap=\"gray\", vmin=0, vmax=1); axs[1,3].axis(\"off\"); axs[1,3].set_title(\"Top-10 Gen\")\n",
        "\n",
        "        # Gen patch w/ stats\n",
        "        arr_gen = model.vocab[tok_gen].cpu().reshape(patch_size,patch_size).numpy()\n",
        "        axs[1,4].imshow(add_colored_border(arr_gen,1,(0,1,0)), cmap=\"gray\", vmin=0, vmax=1)\n",
        "        axs[1,4].axis(\"off\")\n",
        "        axs[1,4].set_title(f\"p={probs_gen[tok_gen]:.3f}\\nΣ_ll={acc_ll_gen:.3f}\\nmode_cnt={mode_count_gen}\")\n",
        "\n",
        "        plt.suptitle(f\"Step {step}, Patch {pidx}\")\n",
        "        frames.append(fig_to_np(fig))\n",
        "        plt.close(fig)\n",
        "\n",
        "    imageio.mimwrite(video_filename, frames, fps=fps)\n",
        "    print(f\"Saved {video_filename}\")\n",
        "\n",
        "    final = patches_to_image(gen_state.cpu(), (image_size, image_size), patch_size)\n",
        "    return final, acc_ll_gen, acc_ll_gt, mode_count_gen, mode_count_gt\n",
        "\n"
      ],
      "metadata": {
        "id": "u6CqKWqF_McY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, ll_sample, ll_given,mode_sample,mode_given = generate_video(model,patch_size,image_size=H,condition_indices=flattened_condition_indices,condition_values=condition_values_new,given_image=samps[334],generation_order=\"inverse manhattan\", temperature=0.9)"
      ],
      "metadata": {
        "id": "qRgAbg6L_Q8t",
        "outputId": "261cac89-8fbe-45ca-c30c-306285373bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: 100%|██████████| 256/256 [04:18<00:00,  1.01s/it]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3120, 1439) to (3120, 1440) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved generation_with_attn.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def stationary_to_full(rel_bias_table: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    rel_bias_table: (2G-1, 2G-1) tensor of stationary biases\n",
        "    returns: (G*G, G*G) full covariance matrix\n",
        "    \"\"\"\n",
        "    # recover G\n",
        "    D = rel_bias_table.shape[0]\n",
        "    assert D % 2 == 1, \"table must be odd-sized\"\n",
        "    G = (D + 1) // 2       # e.g. D=31 -> G=16\n",
        "    N = G * G              # 256\n",
        "\n",
        "    # compute patch grid coordinates 0..G-1\n",
        "    idx = torch.arange(N)\n",
        "    rows = idx // G        # shape (N,)\n",
        "    cols = idx %  G        # shape (N,)\n",
        "\n",
        "    # pairwise differences dr, dc in [-(G-1) .. (G-1)]\n",
        "    dr = rows[:, None] - rows[None, :]   # (N, N)\n",
        "    dc = cols[:, None] - cols[None, :]   # (N, N)\n",
        "\n",
        "    # shift to [0 .. 2G-2] to index into rel_bias_table\n",
        "    ir = dr + (G - 1)    # now in [0 .. 2G-2]\n",
        "    ic = dc + (G - 1)\n",
        "\n",
        "    # gather\n",
        "    full = rel_bias_table[ir, ic]  # (N, N)\n",
        "    return full\n",
        "\n",
        "# example:\n",
        "rel31 = model.rel_bias_table.cpu().detach().numpy()    # your learned table\n",
        "full256 = stationary_to_full(rel31)\n",
        "plt.imshow(full256[:30,:30],cmap=\"seismic\")  # torch.Size([256, 256])\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TViTbevnASiP",
        "outputId": "89139040-e331-417c-9a42-1514ff5bc3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}