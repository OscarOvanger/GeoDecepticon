{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarOvanger/GeoDecepticon/blob/main/training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhDYtsPDKH1Y"
      },
      "source": [
        "# This is where the training goes down"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqn3Jq7vKH1Z"
      },
      "source": [
        " We start of by installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install matplotlib\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "hvzMW1GvKONI",
        "outputId": "ffed18a1-e07b-4779-b787-189b0d1c7054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OscarOvanger/GeoDecepticon.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sSxYr07NGmM",
        "outputId": "d85a7e6e-543b-4ccf-cd3c-fb13b5722a5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GeoDecepticon'...\n",
            "remote: Enumerating objects: 260, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 260 (delta 99), reused 39 (delta 35), pack-reused 100 (from 1)\u001b[K\n",
            "Receiving objects: 100% (260/260), 40.35 MiB | 20.42 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/GeoDecepticon')"
      ],
      "metadata": {
        "id": "C5PNiWOrNTCN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataloader import BinaryImageDataset, preprocess_image\n",
        "from transformer import VisionTransformer\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from sample import reconstruct_image_from_patches\n",
        "import matplotlib.colors as mcolors\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from matplotlib import colors\n",
        "import os\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "uDxei4TeKtU6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1 = np.load(\"data_array_1.npz\")\n",
        "data_2 = np.load(\"data_array_2.npz\")\n",
        "data_3 = np.load(\"data_array_3.npz\")\n",
        "\n",
        "data_array_1 = data_1['data_array']\n",
        "data_array_2 = data_2['data_array']\n",
        "data_array_3 = data_3['data_array']\n",
        "\n",
        "training_data = np.concatenate((data_array_1, data_array_2), axis=0)\n",
        "test_data = data_array_3\n",
        "print(\"training data shape: \", training_data.shape)\n",
        "print(\"test data shape: \", test_data.shape)\n",
        "\n",
        "plt.imshow(training_data[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "q1X8GW0A1vJ2",
        "outputId": "7966e157-5b7d-4a4f-89b7-e3c9378facd3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data shape:  (6000, 64, 64)\n",
            "test data shape:  (3423, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the embedding matrix for all 2x2 binary combinations + 1 mask token\n",
        "embedding_matrix = torch.zeros((17, 4))  # Shape: (num_tokens, embed_dim)\n",
        "\n",
        "# Generate all possible 2x2 binary patches\n",
        "patches = torch.tensor([\n",
        "    [a, b, c, d]\n",
        "    for a in range(2)\n",
        "    for b in range(2)\n",
        "    for c in range(2)\n",
        "    for d in range(2)\n",
        "])  # Shape: (16, 4) for 16 combinations of 2x2 patches\n",
        "\n",
        "# Assign each patch's values as its embedding\n",
        "for i, patch in enumerate(patches):\n",
        "    embedding_matrix[i, :] = patch  # Set the embedding to the patch values\n",
        "\n",
        "# Set the last row to all 2s for the masked patch\n",
        "embedding_matrix[-1, :] = 0.5  # Mask token embedding\n",
        "\n",
        "\n",
        "print(\"Embedding Matrix:\\n\", embedding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVWktkS5DH1S",
        "outputId": "3a7c647d-e322-4afe-df05-fa56d8fc8ac7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix:\n",
            " tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 1.0000],\n",
            "        [0.0000, 0.0000, 1.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 1.0000, 1.0000],\n",
            "        [0.0000, 1.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 1.0000, 0.0000, 1.0000],\n",
            "        [0.0000, 1.0000, 1.0000, 0.0000],\n",
            "        [0.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [1.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [1.0000, 0.0000, 0.0000, 1.0000],\n",
            "        [1.0000, 0.0000, 1.0000, 0.0000],\n",
            "        [1.0000, 0.0000, 1.0000, 1.0000],\n",
            "        [1.0000, 1.0000, 0.0000, 0.0000],\n",
            "        [1.0000, 1.0000, 0.0000, 1.0000],\n",
            "        [1.0000, 1.0000, 1.0000, 0.0000],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [0.5000, 0.5000, 0.5000, 0.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model parameters\n",
        "# Convert to tensors, should be type Long\n",
        "training_images = torch.tensor(training_data, dtype=torch.long)\n",
        "test_images = torch.tensor(test_data, dtype=torch.long)\n",
        "\n",
        "# Parameters\n",
        "batch_size = 30\n",
        "embed_dim = 4\n",
        "num_heads = 2\n",
        "feedforward_dim = 128\n",
        "num_layers = 2\n",
        "num_tokens = 17  # 16 tokens + 1 mask token\n",
        "max_patches = 32 * 32\n",
        "dropout = 0.2\n",
        "learning_rate = 3e-4\n",
        "num_epochs = 500\n",
        "hidden_dim = 32\n",
        "#initial_mask_rate = 0.2\n",
        "#final_mask_rate = 0.1\n",
        "\n",
        "# Dataset and DataLoader\n",
        "dataset = BinaryImageDataset(training_images)  # Assumes training_images is already loaded\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model\n",
        "model = VisionTransformer(embed_dim, num_heads, feedforward_dim, num_layers, num_tokens, max_patches, dropout, hidden_dim).to(device)\n",
        "\n",
        "# Define optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "def prob_log_scheduler(x,max_patches,num_epochs,rand_size):\n",
        "    value = max_patches*np.log((((np.exp(1)-1)*x)/num_epochs) + 1)\n",
        "    i = 0\n",
        "    for val in value:\n",
        "      rand_comp = np.random.randint(-rand_size,rand_size)\n",
        "      #print(\"random value:\", rand_comp)\n",
        "      val = int(val + rand_comp)\n",
        "      if val > max_patches:\n",
        "          val = max_patches\n",
        "      elif val < 1:\n",
        "          val = 1\n",
        "      value[i] = val\n",
        "      i += 1\n",
        "    return value"
      ],
      "metadata": {
        "id": "C5CIDqPjAXWh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(1,num_epochs,num_epochs)\n",
        "max_masking = int(max_patches*0.9)\n",
        "rand_size = 50\n",
        "y = prob_log_scheduler(x,max_masking,num_epochs,rand_size)\n",
        "plt.plot(x,y)\n",
        "plt.title(\"Masking schedule\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Number of masked patches\")\n",
        "plt.show()\n",
        "print(y[0])\n",
        "print(y[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "vE7Hqpmkzj2M",
        "outputId": "b9ff09a9-13df-451e-815d-56bd0702150b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49.0\n",
            "921.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "# Initialize wandb project\n",
        "wandb.init(\n",
        "    project=\"vision-transformer\",\n",
        "    config={\n",
        "        \"batch_size\": batch_size,\n",
        "        \"embed_dim\": embed_dim,\n",
        "        \"num_heads\": num_heads,\n",
        "        \"feedforward_dim\": feedforward_dim,\n",
        "        \"num_layers\": num_layers,\n",
        "        \"num_tokens\": num_tokens,\n",
        "        \"max_patches\": max_patches,\n",
        "        \"dropout\": dropout,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"num_epochs\": num_epochs,\n",
        "        \"hidden_dim\": hidden_dim,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# Directory to save checkpoints\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "maskings = y\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    current_num_mask = int(maskings[epoch])\n",
        "    for batch_idx, images in enumerate(dataloader):\n",
        "        # Preprocess images\n",
        "        patch_indices = torch.stack([preprocess_image(img) for img in images]).long() #(btach_size,max_patches)\n",
        "        masked_patches = patch_indices.clone() #(btach_size,max_patches)\n",
        "\n",
        "        # Generate random indices for masking\n",
        "        random_indices = torch.rand(batch_size, max_patches).argsort(dim=1)[:, :current_num_mask]\n",
        "        # Create the mask tensor\n",
        "        mask = torch.zeros((batch_size, max_patches), dtype=torch.bool)\n",
        "        mask.scatter_(1, random_indices, True)\n",
        "\n",
        "        #Mask\n",
        "        masked_patches[mask] = num_tokens - 1  # Replace masked patches with the mask token\n",
        "\n",
        "        # Define weighted CrossEntropyLoss\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Move to device\n",
        "        masked_patches, patch_indices, mask = (\n",
        "            masked_patches.to(device),\n",
        "            patch_indices.to(device),\n",
        "            mask.to(device),\n",
        "        )\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(masked_patches) # (batch_size,max_patches,num_tokens - 1)\n",
        "        # Isolate the masked patches\n",
        "        # Get the indices of True values\n",
        "        indices = mask.nonzero(as_tuple=True)  # Returns indices where mask is True\n",
        "        # Extract logits at masked positions while maintaining row-wise structure\n",
        "        masked_logits = logits[indices[0], indices[1]]  # Extracts all True-index logits\n",
        "        masked_patch_indices = patch_indices[indices[0], indices[1]]  # Extracts all True-index patch indices\n",
        "        # Reshape to [batch_size, num_masked_patches, num_classes]\n",
        "        masked_logits = masked_logits.view(batch_size, current_num_mask, -1)  # (batch_size, current_num_mask, num_tokens-1)\n",
        "        masked_patch_indices = masked_patch_indices.view(batch_size, current_num_mask) #(batch_size, current_num_mask)\n",
        "        #Compute logits\n",
        "        loss = criterion(masked_logits.view(-1, num_tokens-1), masked_patch_indices.view(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Log batch metrics\n",
        "        wandb.log({\"batch_loss\": loss.item()})\n",
        "\n",
        "        # Initialize a W&B table outside the loop\n",
        "        hist_table = wandb.Table(columns=[\"Masked Patch Index\", \"True Token\", \"Predicted Token\", \"Probability Distribution\"])\n",
        "\n",
        "        # Visualization for the first batch in the epoch\n",
        "        if batch_idx == 0:\n",
        "            with torch.no_grad():\n",
        "                # Initialize predicted_indices with original patch indices\n",
        "                predicted_indices = patch_indices.cpu()[0].clone()  # (max_patches)\n",
        "\n",
        "                # Predict only the masked indices\n",
        "                masked_predictions = torch.argmax(masked_logits, dim=-1).cpu()  # Shape: [batch_size, current_num_mask]\n",
        "                predicted_indices[mask[0]] = masked_predictions[0]  # (current_num_masked)\n",
        "\n",
        "                # Get the probabilities of the masked patches\n",
        "                masked_probs = torch.softmax(masked_logits, dim=-1).cpu().numpy()  # [batch_size, current_num_masked, num_tokens-1]\n",
        "                true_indices = masked_patch_indices[0].cpu().numpy()  # [current_num_masked]\n",
        "                vis_mask = min(current_num_mask, 10)  # Limit visualization to 10 masked patches\n",
        "                masked_probs = masked_probs[:vis_mask]\n",
        "                true_indices = true_indices[:vis_mask]\n",
        "\n",
        "                # Create a W&B Table for histograms of probabilities\n",
        "                hist_table = wandb.Table(columns=[\"Masked Patch Index\", \"True Token\", \"Predicted Token\", \"Probability Distribution\"])\n",
        "                for i in range(vis_mask):\n",
        "                    hist_table.add_data(\n",
        "                        i,  # Masked patch index\n",
        "                        int(true_indices[i]),  # True token for the masked patch\n",
        "                        int(masked_predictions[0][i]),  # Predicted token\n",
        "                        masked_probs[i].tolist()  # Probability distribution\n",
        "                    )\n",
        "                wandb.log({\"Masked Patch Probabilities\": hist_table})\n",
        "\n",
        "\n",
        "                # Reconstruct images\n",
        "                reconstructed_image = reconstruct_image_from_patches(predicted_indices)\n",
        "\n",
        "                # Prepare masked image for visualization\n",
        "                visualized_masked_patches = masked_patches.cpu()[0].clone()\n",
        "                visualized_masked_patches[visualized_masked_patches == num_tokens - 1] = -1\n",
        "                masked_image = reconstruct_image_from_patches(visualized_masked_patches)\n",
        "\n",
        "                # Log visualizations to W&B\n",
        "                wandb.log({\n",
        "                    \"Original Image\": wandb.Image(\n",
        "                        reconstruct_image_from_patches(patch_indices.cpu()[0])\n",
        "                    ),\n",
        "                    \"Masked Image\": wandb.Image(masked_image, caption=\"Masked Image\"),\n",
        "                    \"Reconstructed Image\": wandb.Image(\n",
        "                        reconstructed_image, caption=\"Reconstructed Image\"\n",
        "                    ),\n",
        "                })\n",
        "\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Log epoch metrics\n",
        "    wandb.log({\"epoch_loss\": avg_loss, \"masked_patches\": current_num_mask})\n",
        "\n",
        "    # Save checkpoint periodically\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        checkpoint_path = f\"checkpoints/vision_transformer_epoch_{epoch+1}.pth\"\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"loss\": avg_loss,\n",
        "            },\n",
        "            checkpoint_path,\n",
        "        )\n",
        "        print(f\"Checkpoint saved for epoch {epoch+1}\")\n",
        "        wandb.save(checkpoint_path)\n",
        "\n",
        "# Save the final model\n",
        "torch.save(model.state_dict(), \"vision_transformer_final_balanced.pth\")\n",
        "wandb.save(\"vision_transformer_final_balanced.pth\")\n",
        "print(\"Final model saved as 'vision_transformer_final_balanced.pth'.\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EG-Wyvra6908",
        "outputId": "62a4e212-f7d0-4ebc-acf4-59a55e2021f0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:t4wrgu3m) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▄▄▅▄▃█▄▄▄▄▃▄▃▄▄▃▃▃▃▃▃▄▄▃▃▃▄▃▄▃▃▂▂▄▃▄▃▂▃▁</td></tr><tr><td>epoch_loss</td><td>█▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>masked_patches</td><td>▃▁▁▃▁▁▂▃▁▄▂▃▃▄▂▄▂▃▄▆▆▆▃▄▅▅▄▅▆▆▇▅▇▇▅▆▇█▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.81267</td></tr><tr><td>epoch_loss</td><td>0.82116</td></tr><tr><td>masked_patches</td><td>147</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">misty-moon-46</strong> at: <a href='https://wandb.ai/oscars/vision-transformer/runs/t4wrgu3m' target=\"_blank\">https://wandb.ai/oscars/vision-transformer/runs/t4wrgu3m</a><br/> View project at: <a href='https://wandb.ai/oscars/vision-transformer' target=\"_blank\">https://wandb.ai/oscars/vision-transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 106 artifact file(s) and 213 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241203_094430-t4wrgu3m/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:t4wrgu3m). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/GeoDecepticon/wandb/run-20241203_094911-6uwsapup</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/oscars/vision-transformer/runs/6uwsapup' target=\"_blank\">lunar-shadow-47</a></strong> to <a href='https://wandb.ai/oscars/vision-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/oscars/vision-transformer' target=\"_blank\">https://wandb.ai/oscars/vision-transformer</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/oscars/vision-transformer/runs/6uwsapup' target=\"_blank\">https://wandb.ai/oscars/vision-transformer/runs/6uwsapup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/GeoDecepticon/dataloader.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(image, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500] completed. Average Loss: 0.8114\n",
            "Epoch [2/500] completed. Average Loss: 0.8022\n",
            "Epoch [3/500] completed. Average Loss: 0.8029\n",
            "Epoch [4/500] completed. Average Loss: 0.7955\n",
            "Epoch [5/500] completed. Average Loss: 0.8126\n",
            "Epoch [6/500] completed. Average Loss: 0.7983\n",
            "Epoch [7/500] completed. Average Loss: 0.8476\n",
            "Epoch [8/500] completed. Average Loss: 0.7972\n",
            "Epoch [9/500] completed. Average Loss: 0.7885\n",
            "Epoch [10/500] completed. Average Loss: 0.7885\n",
            "Epoch [11/500] completed. Average Loss: 0.8119\n",
            "Epoch [12/500] completed. Average Loss: 0.7901\n",
            "Epoch [13/500] completed. Average Loss: 0.7866\n",
            "Epoch [14/500] completed. Average Loss: 0.7786\n",
            "Epoch [15/500] completed. Average Loss: 0.7762\n",
            "Epoch [16/500] completed. Average Loss: 0.7766\n",
            "Epoch [17/500] completed. Average Loss: 0.7755\n",
            "Epoch [18/500] completed. Average Loss: 0.7703\n",
            "Epoch [19/500] completed. Average Loss: 0.7728\n",
            "Epoch [20/500] completed. Average Loss: 0.7719\n",
            "Epoch [21/500] completed. Average Loss: 0.7625\n",
            "Epoch [22/500] completed. Average Loss: 0.7578\n",
            "Epoch [23/500] completed. Average Loss: 0.7518\n",
            "Epoch [24/500] completed. Average Loss: 0.7548\n",
            "Epoch [25/500] completed. Average Loss: 0.7498\n",
            "Epoch [26/500] completed. Average Loss: 0.7498\n",
            "Epoch [27/500] completed. Average Loss: 0.7412\n",
            "Epoch [28/500] completed. Average Loss: 0.7380\n",
            "Epoch [29/500] completed. Average Loss: 0.7355\n",
            "Epoch [30/500] completed. Average Loss: 0.7244\n",
            "Epoch [31/500] completed. Average Loss: 0.7231\n",
            "Epoch [32/500] completed. Average Loss: 0.7203\n",
            "Epoch [33/500] completed. Average Loss: 0.7170\n",
            "Epoch [34/500] completed. Average Loss: 0.7111\n",
            "Epoch [35/500] completed. Average Loss: 0.7036\n",
            "Epoch [36/500] completed. Average Loss: 0.7005\n",
            "Epoch [37/500] completed. Average Loss: 0.6993\n",
            "Epoch [38/500] completed. Average Loss: 0.6936\n",
            "Epoch [39/500] completed. Average Loss: 0.6848\n",
            "Epoch [40/500] completed. Average Loss: 0.6849\n",
            "Epoch [41/500] completed. Average Loss: 0.6742\n",
            "Epoch [42/500] completed. Average Loss: 0.6766\n",
            "Epoch [43/500] completed. Average Loss: 0.6706\n",
            "Epoch [44/500] completed. Average Loss: 0.6617\n",
            "Epoch [45/500] completed. Average Loss: 0.6614\n",
            "Epoch [46/500] completed. Average Loss: 0.6566\n",
            "Epoch [47/500] completed. Average Loss: 0.6559\n",
            "Epoch [48/500] completed. Average Loss: 0.6497\n",
            "Epoch [49/500] completed. Average Loss: 0.6521\n",
            "Epoch [50/500] completed. Average Loss: 0.6435\n",
            "Checkpoint saved for epoch 50\n",
            "Epoch [51/500] completed. Average Loss: 0.6383\n",
            "Epoch [52/500] completed. Average Loss: 0.6375\n",
            "Epoch [53/500] completed. Average Loss: 0.6345\n",
            "Epoch [54/500] completed. Average Loss: 0.6363\n",
            "Epoch [55/500] completed. Average Loss: 0.6326\n",
            "Epoch [56/500] completed. Average Loss: 0.6259\n",
            "Epoch [57/500] completed. Average Loss: 0.6194\n",
            "Epoch [58/500] completed. Average Loss: 0.6247\n",
            "Epoch [59/500] completed. Average Loss: 0.6176\n",
            "Epoch [60/500] completed. Average Loss: 0.6084\n",
            "Epoch [61/500] completed. Average Loss: 0.6141\n",
            "Epoch [62/500] completed. Average Loss: 0.6081\n",
            "Epoch [63/500] completed. Average Loss: 0.6083\n",
            "Epoch [64/500] completed. Average Loss: 0.6049\n",
            "Epoch [65/500] completed. Average Loss: 0.5938\n",
            "Epoch [66/500] completed. Average Loss: 0.5925\n",
            "Epoch [67/500] completed. Average Loss: 0.5943\n",
            "Epoch [68/500] completed. Average Loss: 0.5871\n",
            "Epoch [69/500] completed. Average Loss: 0.5819\n",
            "Epoch [70/500] completed. Average Loss: 0.5803\n",
            "Epoch [71/500] completed. Average Loss: 0.5785\n",
            "Epoch [72/500] completed. Average Loss: 0.5723\n",
            "Epoch [73/500] completed. Average Loss: 0.5674\n",
            "Epoch [74/500] completed. Average Loss: 0.5683\n",
            "Epoch [75/500] completed. Average Loss: 0.5567\n",
            "Epoch [76/500] completed. Average Loss: 0.5627\n",
            "Epoch [77/500] completed. Average Loss: 0.5540\n",
            "Epoch [78/500] completed. Average Loss: 0.5558\n",
            "Epoch [79/500] completed. Average Loss: 0.5522\n",
            "Epoch [80/500] completed. Average Loss: 0.5496\n",
            "Epoch [81/500] completed. Average Loss: 0.5480\n",
            "Epoch [82/500] completed. Average Loss: 0.5470\n",
            "Epoch [83/500] completed. Average Loss: 0.5400\n",
            "Epoch [84/500] completed. Average Loss: 0.5387\n",
            "Epoch [85/500] completed. Average Loss: 0.5366\n",
            "Epoch [86/500] completed. Average Loss: 0.5361\n",
            "Epoch [87/500] completed. Average Loss: 0.5337\n",
            "Epoch [88/500] completed. Average Loss: 0.5225\n",
            "Epoch [89/500] completed. Average Loss: 0.5226\n",
            "Epoch [90/500] completed. Average Loss: 0.5209\n",
            "Epoch [91/500] completed. Average Loss: 0.5190\n",
            "Epoch [92/500] completed. Average Loss: 0.5145\n",
            "Epoch [93/500] completed. Average Loss: 0.5205\n",
            "Epoch [94/500] completed. Average Loss: 0.5195\n",
            "Epoch [95/500] completed. Average Loss: 0.5132\n",
            "Epoch [96/500] completed. Average Loss: 0.5149\n",
            "Epoch [97/500] completed. Average Loss: 0.5057\n",
            "Epoch [98/500] completed. Average Loss: 0.5056\n",
            "Epoch [99/500] completed. Average Loss: 0.5094\n",
            "Epoch [100/500] completed. Average Loss: 0.5060\n",
            "Checkpoint saved for epoch 100\n",
            "Epoch [101/500] completed. Average Loss: 0.5002\n",
            "Epoch [102/500] completed. Average Loss: 0.5021\n",
            "Epoch [103/500] completed. Average Loss: 0.5040\n",
            "Epoch [104/500] completed. Average Loss: 0.4956\n",
            "Epoch [105/500] completed. Average Loss: 0.4866\n",
            "Epoch [106/500] completed. Average Loss: 0.4852\n",
            "Epoch [107/500] completed. Average Loss: 0.4928\n",
            "Epoch [108/500] completed. Average Loss: 0.4880\n",
            "Epoch [109/500] completed. Average Loss: 0.4888\n",
            "Epoch [110/500] completed. Average Loss: 0.4932\n",
            "Epoch [111/500] completed. Average Loss: 0.4871\n",
            "Epoch [112/500] completed. Average Loss: 0.4871\n",
            "Epoch [113/500] completed. Average Loss: 0.4858\n",
            "Epoch [114/500] completed. Average Loss: 0.4840\n",
            "Epoch [115/500] completed. Average Loss: 0.4780\n",
            "Epoch [116/500] completed. Average Loss: 0.4731\n",
            "Epoch [117/500] completed. Average Loss: 0.4785\n",
            "Epoch [118/500] completed. Average Loss: 0.4670\n",
            "Epoch [119/500] completed. Average Loss: 0.4640\n",
            "Epoch [120/500] completed. Average Loss: 0.4747\n",
            "Epoch [121/500] completed. Average Loss: 0.4633\n",
            "Epoch [122/500] completed. Average Loss: 0.4731\n",
            "Epoch [123/500] completed. Average Loss: 0.4662\n",
            "Epoch [124/500] completed. Average Loss: 0.4600\n",
            "Epoch [125/500] completed. Average Loss: 0.4657\n",
            "Epoch [126/500] completed. Average Loss: 0.4639\n",
            "Epoch [127/500] completed. Average Loss: 0.4575\n",
            "Epoch [128/500] completed. Average Loss: 0.4578\n",
            "Epoch [129/500] completed. Average Loss: 0.4661\n",
            "Epoch [130/500] completed. Average Loss: 0.4541\n",
            "Epoch [131/500] completed. Average Loss: 0.4570\n",
            "Epoch [132/500] completed. Average Loss: 0.4543\n",
            "Epoch [133/500] completed. Average Loss: 0.4653\n",
            "Epoch [134/500] completed. Average Loss: 0.4564\n",
            "Epoch [135/500] completed. Average Loss: 0.4489\n",
            "Epoch [136/500] completed. Average Loss: 0.4489\n",
            "Epoch [137/500] completed. Average Loss: 0.4580\n",
            "Epoch [138/500] completed. Average Loss: 0.4483\n",
            "Epoch [139/500] completed. Average Loss: 0.4476\n",
            "Epoch [140/500] completed. Average Loss: 0.4482\n",
            "Epoch [141/500] completed. Average Loss: 0.4431\n",
            "Epoch [142/500] completed. Average Loss: 0.4454\n",
            "Epoch [143/500] completed. Average Loss: 0.4551\n",
            "Epoch [144/500] completed. Average Loss: 0.4412\n",
            "Epoch [145/500] completed. Average Loss: 0.4510\n",
            "Epoch [146/500] completed. Average Loss: 0.4481\n",
            "Epoch [147/500] completed. Average Loss: 0.4445\n",
            "Epoch [148/500] completed. Average Loss: 0.4467\n",
            "Epoch [149/500] completed. Average Loss: 0.4509\n",
            "Epoch [150/500] completed. Average Loss: 0.4471\n",
            "Checkpoint saved for epoch 150\n",
            "Epoch [151/500] completed. Average Loss: 0.4464\n",
            "Epoch [152/500] completed. Average Loss: 0.4416\n",
            "Epoch [153/500] completed. Average Loss: 0.4392\n",
            "Epoch [154/500] completed. Average Loss: 0.4354\n",
            "Epoch [155/500] completed. Average Loss: 0.4398\n",
            "Epoch [156/500] completed. Average Loss: 0.4498\n",
            "Epoch [157/500] completed. Average Loss: 0.4337\n",
            "Epoch [158/500] completed. Average Loss: 0.4542\n",
            "Epoch [159/500] completed. Average Loss: 0.4379\n",
            "Epoch [160/500] completed. Average Loss: 0.4498\n",
            "Epoch [161/500] completed. Average Loss: 0.4480\n",
            "Epoch [162/500] completed. Average Loss: 0.4432\n",
            "Epoch [163/500] completed. Average Loss: 0.4494\n",
            "Epoch [164/500] completed. Average Loss: 0.4515\n",
            "Epoch [165/500] completed. Average Loss: 0.4347\n",
            "Epoch [166/500] completed. Average Loss: 0.4481\n",
            "Epoch [167/500] completed. Average Loss: 0.4390\n",
            "Epoch [168/500] completed. Average Loss: 0.4511\n",
            "Epoch [169/500] completed. Average Loss: 0.4439\n",
            "Epoch [170/500] completed. Average Loss: 0.4394\n",
            "Epoch [171/500] completed. Average Loss: 0.4389\n",
            "Epoch [172/500] completed. Average Loss: 0.4430\n",
            "Epoch [173/500] completed. Average Loss: 0.4487\n",
            "Epoch [174/500] completed. Average Loss: 0.4509\n",
            "Epoch [175/500] completed. Average Loss: 0.4403\n",
            "Epoch [176/500] completed. Average Loss: 0.4492\n",
            "Epoch [177/500] completed. Average Loss: 0.4405\n",
            "Epoch [178/500] completed. Average Loss: 0.4403\n",
            "Epoch [179/500] completed. Average Loss: 0.4428\n",
            "Epoch [180/500] completed. Average Loss: 0.4306\n",
            "Epoch [181/500] completed. Average Loss: 0.4484\n",
            "Epoch [182/500] completed. Average Loss: 0.4428\n",
            "Epoch [183/500] completed. Average Loss: 0.4417\n",
            "Epoch [184/500] completed. Average Loss: 0.4403\n",
            "Epoch [185/500] completed. Average Loss: 0.4382\n",
            "Epoch [186/500] completed. Average Loss: 0.4331\n",
            "Epoch [187/500] completed. Average Loss: 0.4435\n",
            "Epoch [188/500] completed. Average Loss: 0.4438\n",
            "Epoch [189/500] completed. Average Loss: 0.4330\n",
            "Epoch [190/500] completed. Average Loss: 0.4321\n",
            "Epoch [191/500] completed. Average Loss: 0.4477\n",
            "Epoch [192/500] completed. Average Loss: 0.4388\n",
            "Epoch [193/500] completed. Average Loss: 0.4467\n",
            "Epoch [194/500] completed. Average Loss: 0.4334\n",
            "Epoch [195/500] completed. Average Loss: 0.4359\n",
            "Epoch [196/500] completed. Average Loss: 0.4375\n",
            "Epoch [197/500] completed. Average Loss: 0.4380\n",
            "Epoch [198/500] completed. Average Loss: 0.4433\n",
            "Epoch [199/500] completed. Average Loss: 0.4477\n",
            "Epoch [200/500] completed. Average Loss: 0.4420\n",
            "Checkpoint saved for epoch 200\n",
            "Epoch [201/500] completed. Average Loss: 0.4347\n",
            "Epoch [202/500] completed. Average Loss: 0.4498\n",
            "Epoch [203/500] completed. Average Loss: 0.4517\n",
            "Epoch [204/500] completed. Average Loss: 0.4393\n",
            "Epoch [205/500] completed. Average Loss: 0.4414\n",
            "Epoch [206/500] completed. Average Loss: 0.4487\n",
            "Epoch [207/500] completed. Average Loss: 0.4500\n",
            "Epoch [208/500] completed. Average Loss: 0.4477\n",
            "Epoch [209/500] completed. Average Loss: 0.4479\n",
            "Epoch [210/500] completed. Average Loss: 0.4502\n",
            "Epoch [211/500] completed. Average Loss: 0.4361\n",
            "Epoch [212/500] completed. Average Loss: 0.4436\n",
            "Epoch [213/500] completed. Average Loss: 0.4499\n",
            "Epoch [214/500] completed. Average Loss: 0.4529\n",
            "Epoch [215/500] completed. Average Loss: 0.4496\n",
            "Epoch [216/500] completed. Average Loss: 0.4479\n",
            "Epoch [217/500] completed. Average Loss: 0.4420\n",
            "Epoch [218/500] completed. Average Loss: 0.4546\n",
            "Epoch [219/500] completed. Average Loss: 0.4400\n",
            "Epoch [220/500] completed. Average Loss: 0.4523\n",
            "Epoch [221/500] completed. Average Loss: 0.4482\n",
            "Epoch [222/500] completed. Average Loss: 0.4362\n",
            "Epoch [223/500] completed. Average Loss: 0.4545\n",
            "Epoch [224/500] completed. Average Loss: 0.4394\n",
            "Epoch [225/500] completed. Average Loss: 0.4607\n",
            "Epoch [226/500] completed. Average Loss: 0.4500\n",
            "Epoch [227/500] completed. Average Loss: 0.4580\n",
            "Epoch [228/500] completed. Average Loss: 0.4424\n",
            "Epoch [229/500] completed. Average Loss: 0.4491\n",
            "Epoch [230/500] completed. Average Loss: 0.4636\n",
            "Epoch [231/500] completed. Average Loss: 0.4603\n",
            "Epoch [232/500] completed. Average Loss: 0.4395\n",
            "Epoch [233/500] completed. Average Loss: 0.4645\n",
            "Epoch [234/500] completed. Average Loss: 0.4628\n",
            "Epoch [235/500] completed. Average Loss: 0.4656\n",
            "Epoch [236/500] completed. Average Loss: 0.4415\n",
            "Epoch [237/500] completed. Average Loss: 0.4587\n",
            "Epoch [238/500] completed. Average Loss: 0.4662\n",
            "Epoch [239/500] completed. Average Loss: 0.4625\n",
            "Epoch [240/500] completed. Average Loss: 0.4504\n",
            "Epoch [241/500] completed. Average Loss: 0.4453\n",
            "Epoch [242/500] completed. Average Loss: 0.4412\n",
            "Epoch [243/500] completed. Average Loss: 0.4666\n",
            "Epoch [244/500] completed. Average Loss: 0.4683\n",
            "Epoch [245/500] completed. Average Loss: 0.4640\n",
            "Epoch [246/500] completed. Average Loss: 0.4627\n",
            "Epoch [247/500] completed. Average Loss: 0.4566\n",
            "Epoch [248/500] completed. Average Loss: 0.4437\n",
            "Epoch [249/500] completed. Average Loss: 0.4531\n",
            "Epoch [250/500] completed. Average Loss: 0.4541\n",
            "Checkpoint saved for epoch 250\n",
            "Epoch [251/500] completed. Average Loss: 0.4594\n",
            "Epoch [252/500] completed. Average Loss: 0.4525\n",
            "Epoch [253/500] completed. Average Loss: 0.4638\n",
            "Epoch [254/500] completed. Average Loss: 0.4463\n",
            "Epoch [255/500] completed. Average Loss: 0.4458\n",
            "Epoch [256/500] completed. Average Loss: 0.4509\n",
            "Epoch [257/500] completed. Average Loss: 0.4491\n",
            "Epoch [258/500] completed. Average Loss: 0.4516\n",
            "Epoch [259/500] completed. Average Loss: 0.4708\n",
            "Epoch [260/500] completed. Average Loss: 0.4508\n",
            "Epoch [261/500] completed. Average Loss: 0.4719\n",
            "Epoch [262/500] completed. Average Loss: 0.4699\n",
            "Epoch [263/500] completed. Average Loss: 0.4511\n",
            "Epoch [264/500] completed. Average Loss: 0.4680\n",
            "Epoch [265/500] completed. Average Loss: 0.4627\n",
            "Epoch [266/500] completed. Average Loss: 0.4471\n",
            "Epoch [267/500] completed. Average Loss: 0.4635\n",
            "Epoch [268/500] completed. Average Loss: 0.4523\n",
            "Epoch [269/500] completed. Average Loss: 0.4640\n",
            "Epoch [270/500] completed. Average Loss: 0.4739\n",
            "Epoch [271/500] completed. Average Loss: 0.4573\n",
            "Epoch [272/500] completed. Average Loss: 0.4672\n",
            "Epoch [273/500] completed. Average Loss: 0.4762\n",
            "Epoch [274/500] completed. Average Loss: 0.4726\n",
            "Epoch [275/500] completed. Average Loss: 0.4535\n",
            "Epoch [276/500] completed. Average Loss: 0.4695\n",
            "Epoch [277/500] completed. Average Loss: 0.4789\n",
            "Epoch [278/500] completed. Average Loss: 0.4567\n",
            "Epoch [279/500] completed. Average Loss: 0.4659\n",
            "Epoch [280/500] completed. Average Loss: 0.4703\n",
            "Epoch [281/500] completed. Average Loss: 0.4644\n",
            "Epoch [282/500] completed. Average Loss: 0.4658\n",
            "Epoch [283/500] completed. Average Loss: 0.4677\n",
            "Epoch [284/500] completed. Average Loss: 0.4698\n",
            "Epoch [285/500] completed. Average Loss: 0.4835\n",
            "Epoch [286/500] completed. Average Loss: 0.4758\n",
            "Epoch [287/500] completed. Average Loss: 0.4536\n",
            "Epoch [288/500] completed. Average Loss: 0.4577\n",
            "Epoch [289/500] completed. Average Loss: 0.4845\n",
            "Epoch [290/500] completed. Average Loss: 0.4731\n",
            "Epoch [291/500] completed. Average Loss: 0.4643\n",
            "Epoch [292/500] completed. Average Loss: 0.4735\n",
            "Epoch [293/500] completed. Average Loss: 0.4819\n",
            "Epoch [294/500] completed. Average Loss: 0.4835\n",
            "Epoch [295/500] completed. Average Loss: 0.4643\n",
            "Epoch [296/500] completed. Average Loss: 0.4583\n",
            "Epoch [297/500] completed. Average Loss: 0.4882\n",
            "Epoch [298/500] completed. Average Loss: 0.4818\n",
            "Epoch [299/500] completed. Average Loss: 0.4632\n",
            "Epoch [300/500] completed. Average Loss: 0.4654\n",
            "Checkpoint saved for epoch 300\n",
            "Epoch [301/500] completed. Average Loss: 0.4728\n",
            "Epoch [302/500] completed. Average Loss: 0.4644\n",
            "Epoch [303/500] completed. Average Loss: 0.4625\n",
            "Epoch [304/500] completed. Average Loss: 0.4594\n",
            "Epoch [305/500] completed. Average Loss: 0.4807\n",
            "Epoch [306/500] completed. Average Loss: 0.4683\n",
            "Epoch [307/500] completed. Average Loss: 0.4607\n",
            "Epoch [308/500] completed. Average Loss: 0.4879\n",
            "Epoch [309/500] completed. Average Loss: 0.4729\n",
            "Epoch [310/500] completed. Average Loss: 0.4617\n",
            "Epoch [311/500] completed. Average Loss: 0.4612\n",
            "Epoch [312/500] completed. Average Loss: 0.4879\n",
            "Epoch [313/500] completed. Average Loss: 0.4925\n",
            "Epoch [314/500] completed. Average Loss: 0.4893\n",
            "Epoch [315/500] completed. Average Loss: 0.4796\n",
            "Epoch [316/500] completed. Average Loss: 0.4636\n",
            "Epoch [317/500] completed. Average Loss: 0.4959\n",
            "Epoch [318/500] completed. Average Loss: 0.4968\n",
            "Epoch [319/500] completed. Average Loss: 0.4775\n",
            "Epoch [320/500] completed. Average Loss: 0.5007\n",
            "Epoch [321/500] completed. Average Loss: 0.4964\n",
            "Epoch [322/500] completed. Average Loss: 0.4980\n",
            "Epoch [323/500] completed. Average Loss: 0.4775\n",
            "Epoch [324/500] completed. Average Loss: 0.4927\n",
            "Epoch [325/500] completed. Average Loss: 0.4688\n",
            "Epoch [326/500] completed. Average Loss: 0.4877\n",
            "Epoch [327/500] completed. Average Loss: 0.4765\n",
            "Epoch [328/500] completed. Average Loss: 0.4891\n",
            "Epoch [329/500] completed. Average Loss: 0.4934\n",
            "Epoch [330/500] completed. Average Loss: 0.4809\n",
            "Epoch [331/500] completed. Average Loss: 0.4854\n",
            "Epoch [332/500] completed. Average Loss: 0.4707\n",
            "Epoch [333/500] completed. Average Loss: 0.4929\n",
            "Epoch [334/500] completed. Average Loss: 0.4854\n",
            "Epoch [335/500] completed. Average Loss: 0.4865\n",
            "Epoch [336/500] completed. Average Loss: 0.5017\n",
            "Epoch [337/500] completed. Average Loss: 0.5003\n",
            "Epoch [338/500] completed. Average Loss: 0.5061\n",
            "Epoch [339/500] completed. Average Loss: 0.4745\n",
            "Epoch [340/500] completed. Average Loss: 0.5068\n",
            "Epoch [341/500] completed. Average Loss: 0.5031\n",
            "Epoch [342/500] completed. Average Loss: 0.4755\n",
            "Epoch [343/500] completed. Average Loss: 0.4934\n",
            "Epoch [344/500] completed. Average Loss: 0.5116\n",
            "Epoch [345/500] completed. Average Loss: 0.4863\n",
            "Epoch [346/500] completed. Average Loss: 0.5027\n",
            "Epoch [347/500] completed. Average Loss: 0.4980\n",
            "Epoch [348/500] completed. Average Loss: 0.4838\n",
            "Epoch [349/500] completed. Average Loss: 0.5069\n",
            "Epoch [350/500] completed. Average Loss: 0.5057\n",
            "Checkpoint saved for epoch 350\n",
            "Epoch [351/500] completed. Average Loss: 0.4942\n",
            "Epoch [352/500] completed. Average Loss: 0.4781\n",
            "Epoch [353/500] completed. Average Loss: 0.5071\n",
            "Epoch [354/500] completed. Average Loss: 0.4927\n",
            "Epoch [355/500] completed. Average Loss: 0.5105\n",
            "Epoch [356/500] completed. Average Loss: 0.4803\n",
            "Epoch [357/500] completed. Average Loss: 0.4823\n",
            "Epoch [358/500] completed. Average Loss: 0.5135\n",
            "Epoch [359/500] completed. Average Loss: 0.4818\n",
            "Epoch [360/500] completed. Average Loss: 0.5032\n",
            "Epoch [361/500] completed. Average Loss: 0.4853\n",
            "Epoch [362/500] completed. Average Loss: 0.5008\n",
            "Epoch [363/500] completed. Average Loss: 0.4850\n",
            "Epoch [364/500] completed. Average Loss: 0.5169\n",
            "Epoch [365/500] completed. Average Loss: 0.5059\n",
            "Epoch [366/500] completed. Average Loss: 0.5160\n",
            "Epoch [367/500] completed. Average Loss: 0.5004\n",
            "Epoch [368/500] completed. Average Loss: 0.5087\n",
            "Epoch [369/500] completed. Average Loss: 0.5193\n",
            "Epoch [370/500] completed. Average Loss: 0.5111\n",
            "Epoch [371/500] completed. Average Loss: 0.5220\n",
            "Epoch [372/500] completed. Average Loss: 0.5103\n",
            "Epoch [373/500] completed. Average Loss: 0.5100\n",
            "Epoch [374/500] completed. Average Loss: 0.5196\n",
            "Epoch [375/500] completed. Average Loss: 0.4893\n",
            "Epoch [376/500] completed. Average Loss: 0.4876\n",
            "Epoch [377/500] completed. Average Loss: 0.4880\n",
            "Epoch [378/500] completed. Average Loss: 0.5337\n",
            "Epoch [379/500] completed. Average Loss: 0.5137\n",
            "Epoch [380/500] completed. Average Loss: 0.4964\n",
            "Epoch [381/500] completed. Average Loss: 0.4986\n",
            "Epoch [382/500] completed. Average Loss: 0.4923\n",
            "Epoch [383/500] completed. Average Loss: 0.5146\n",
            "Epoch [384/500] completed. Average Loss: 0.5190\n",
            "Epoch [385/500] completed. Average Loss: 0.5218\n",
            "Epoch [386/500] completed. Average Loss: 0.5430\n",
            "Epoch [387/500] completed. Average Loss: 0.4957\n",
            "Epoch [388/500] completed. Average Loss: 0.5242\n",
            "Epoch [389/500] completed. Average Loss: 0.5223\n",
            "Epoch [390/500] completed. Average Loss: 0.5320\n",
            "Epoch [391/500] completed. Average Loss: 0.5317\n",
            "Epoch [392/500] completed. Average Loss: 0.5196\n",
            "Epoch [393/500] completed. Average Loss: 0.5401\n",
            "Epoch [394/500] completed. Average Loss: 0.5099\n",
            "Epoch [395/500] completed. Average Loss: 0.4973\n",
            "Epoch [396/500] completed. Average Loss: 0.5245\n",
            "Epoch [397/500] completed. Average Loss: 0.5232\n",
            "Epoch [398/500] completed. Average Loss: 0.5374\n",
            "Epoch [399/500] completed. Average Loss: 0.5209\n",
            "Epoch [400/500] completed. Average Loss: 0.5272\n",
            "Checkpoint saved for epoch 400\n",
            "Epoch [401/500] completed. Average Loss: 0.5258\n",
            "Epoch [402/500] completed. Average Loss: 0.5335\n",
            "Epoch [403/500] completed. Average Loss: 0.5166\n",
            "Epoch [404/500] completed. Average Loss: 0.5224\n",
            "Epoch [405/500] completed. Average Loss: 0.5468\n",
            "Epoch [406/500] completed. Average Loss: 0.5338\n",
            "Epoch [407/500] completed. Average Loss: 0.5138\n",
            "Epoch [408/500] completed. Average Loss: 0.5528\n",
            "Epoch [409/500] completed. Average Loss: 0.5397\n",
            "Epoch [410/500] completed. Average Loss: 0.5295\n",
            "Epoch [411/500] completed. Average Loss: 0.5098\n",
            "Epoch [412/500] completed. Average Loss: 0.5447\n",
            "Epoch [413/500] completed. Average Loss: 0.5281\n",
            "Epoch [414/500] completed. Average Loss: 0.5063\n",
            "Epoch [415/500] completed. Average Loss: 0.5488\n",
            "Epoch [416/500] completed. Average Loss: 0.5180\n",
            "Epoch [417/500] completed. Average Loss: 0.5655\n",
            "Epoch [418/500] completed. Average Loss: 0.5355\n",
            "Epoch [419/500] completed. Average Loss: 0.5084\n",
            "Epoch [420/500] completed. Average Loss: 0.5249\n",
            "Epoch [421/500] completed. Average Loss: 0.5350\n",
            "Epoch [422/500] completed. Average Loss: 0.5403\n",
            "Epoch [423/500] completed. Average Loss: 0.5098\n",
            "Epoch [424/500] completed. Average Loss: 0.5509\n",
            "Epoch [425/500] completed. Average Loss: 0.5224\n",
            "Epoch [426/500] completed. Average Loss: 0.5190\n",
            "Epoch [427/500] completed. Average Loss: 0.5322\n",
            "Epoch [428/500] completed. Average Loss: 0.5600\n",
            "Epoch [429/500] completed. Average Loss: 0.5165\n",
            "Epoch [430/500] completed. Average Loss: 0.5302\n",
            "Epoch [431/500] completed. Average Loss: 0.5480\n",
            "Epoch [432/500] completed. Average Loss: 0.5722\n",
            "Epoch [433/500] completed. Average Loss: 0.5755\n",
            "Epoch [434/500] completed. Average Loss: 0.5340\n",
            "Epoch [435/500] completed. Average Loss: 0.5199\n",
            "Epoch [436/500] completed. Average Loss: 0.5197\n",
            "Epoch [437/500] completed. Average Loss: 0.5602\n",
            "Epoch [438/500] completed. Average Loss: 0.5902\n",
            "Epoch [439/500] completed. Average Loss: 0.5209\n",
            "Epoch [440/500] completed. Average Loss: 0.5677\n",
            "Epoch [441/500] completed. Average Loss: 0.5786\n",
            "Epoch [442/500] completed. Average Loss: 0.5863\n",
            "Epoch [443/500] completed. Average Loss: 0.5764\n",
            "Epoch [444/500] completed. Average Loss: 0.5868\n",
            "Epoch [445/500] completed. Average Loss: 0.5273\n",
            "Epoch [446/500] completed. Average Loss: 0.5465\n",
            "Epoch [447/500] completed. Average Loss: 0.5578\n",
            "Epoch [448/500] completed. Average Loss: 0.5393\n",
            "Epoch [449/500] completed. Average Loss: 0.5665\n",
            "Epoch [450/500] completed. Average Loss: 0.5414\n",
            "Checkpoint saved for epoch 450\n",
            "Epoch [451/500] completed. Average Loss: 0.5706\n",
            "Epoch [452/500] completed. Average Loss: 0.5427\n",
            "Epoch [453/500] completed. Average Loss: 0.5847\n",
            "Epoch [454/500] completed. Average Loss: 0.5646\n",
            "Epoch [455/500] completed. Average Loss: 0.5618\n",
            "Epoch [456/500] completed. Average Loss: 0.5481\n",
            "Epoch [457/500] completed. Average Loss: 0.5479\n",
            "Epoch [458/500] completed. Average Loss: 0.5908\n",
            "Epoch [459/500] completed. Average Loss: 0.5744\n",
            "Epoch [460/500] completed. Average Loss: 0.5665\n",
            "Epoch [461/500] completed. Average Loss: 0.6173\n",
            "Epoch [462/500] completed. Average Loss: 0.6046\n",
            "Epoch [463/500] completed. Average Loss: 0.5506\n",
            "Epoch [464/500] completed. Average Loss: 0.5823\n",
            "Epoch [465/500] completed. Average Loss: 0.5374\n",
            "Epoch [466/500] completed. Average Loss: 0.6227\n",
            "Epoch [467/500] completed. Average Loss: 0.6119\n",
            "Epoch [468/500] completed. Average Loss: 0.5806\n",
            "Epoch [469/500] completed. Average Loss: 0.6202\n",
            "Epoch [470/500] completed. Average Loss: 0.6169\n",
            "Epoch [471/500] completed. Average Loss: 0.6147\n",
            "Epoch [472/500] completed. Average Loss: 0.5721\n",
            "Epoch [473/500] completed. Average Loss: 0.5427\n",
            "Epoch [474/500] completed. Average Loss: 0.6116\n",
            "Epoch [475/500] completed. Average Loss: 0.5586\n",
            "Epoch [476/500] completed. Average Loss: 0.5657\n",
            "Epoch [477/500] completed. Average Loss: 0.6188\n",
            "Epoch [478/500] completed. Average Loss: 0.5747\n",
            "Epoch [479/500] completed. Average Loss: 0.6186\n",
            "Epoch [480/500] completed. Average Loss: 0.6168\n",
            "Epoch [481/500] completed. Average Loss: 0.5530\n",
            "Epoch [482/500] completed. Average Loss: 0.6180\n",
            "Epoch [483/500] completed. Average Loss: 0.5701\n",
            "Epoch [484/500] completed. Average Loss: 0.5522\n",
            "Epoch [485/500] completed. Average Loss: 0.5852\n",
            "Epoch [486/500] completed. Average Loss: 0.6172\n",
            "Epoch [487/500] completed. Average Loss: 0.6172\n",
            "Epoch [488/500] completed. Average Loss: 0.6162\n",
            "Epoch [489/500] completed. Average Loss: 0.5629\n",
            "Epoch [490/500] completed. Average Loss: 0.6161\n",
            "Epoch [491/500] completed. Average Loss: 0.6158\n",
            "Epoch [492/500] completed. Average Loss: 0.6150\n",
            "Epoch [493/500] completed. Average Loss: 0.5578\n",
            "Epoch [494/500] completed. Average Loss: 0.6154\n",
            "Epoch [495/500] completed. Average Loss: 0.6148\n",
            "Epoch [496/500] completed. Average Loss: 0.6142\n",
            "Epoch [497/500] completed. Average Loss: 0.6075\n",
            "Epoch [498/500] completed. Average Loss: 0.5656\n",
            "Epoch [499/500] completed. Average Loss: 0.6137\n",
            "Epoch [500/500] completed. Average Loss: 0.6141\n",
            "Checkpoint saved for epoch 500\n",
            "Final model saved as 'vision_transformer_final_balanced.pth'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▆█▇▅▅▃▃▂▂▁▂▂▂▁▂▂▂▁▁▂▂▂▃▂▂▂▄▂▃▃▃▃▃▃▂▃▃▂▃▂</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▄▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▂▃▃▃▃▄▄▄▄▄</td></tr><tr><td>masked_patches</td><td>▁▁▁▂▂▃▂▃▃▃▃▃▃▄▃▄▄▄▅▄▅▅▅▅▅▆▆▆▇▆▇▇▇▇▇█▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.56779</td></tr><tr><td>epoch_loss</td><td>0.61414</td></tr><tr><td>masked_patches</td><td>921</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lunar-shadow-47</strong> at: <a href='https://wandb.ai/oscars/vision-transformer/runs/6uwsapup' target=\"_blank\">https://wandb.ai/oscars/vision-transformer/runs/6uwsapup</a><br/> View project at: <a href='https://wandb.ai/oscars/vision-transformer' target=\"_blank\">https://wandb.ai/oscars/vision-transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 1000 artifact file(s) and 2011 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241203_094911-6uwsapup/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling"
      ],
      "metadata": {
        "id": "KZAVOTHq5u5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model.load_state_dict(torch.load(\"vision_transformer_final_balanced.pth\"))\n",
        "model.eval()\n",
        "# Load the first image from the test data\n",
        "# Dataset and DataLoader\n",
        "current_num_mask = 900\n",
        "batch_size = 1\n",
        "dataset = BinaryImageDataset(test_images)  # Assumes training_images is already loaded\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "batch_idx, test_images = next(enumerate(dataloader))\n",
        "first_image = test_images[0]\n",
        "plt.imshow(first_image,cmap='gray')\n",
        "plt.title(\"First image in test dataset\")\n",
        "plt.show()\n",
        "\n",
        "# Preprocess images\n",
        "patch_indices = torch.stack([preprocess_image(img) for img in test_images]).long() #(batch_size,max_patches)\n",
        "masked_patches = patch_indices.clone() #(batch_size,max_patches)\n",
        "\n",
        "# Generate random indices for masking\n",
        "random_indices = torch.rand(batch_size, max_patches).argsort(dim=1)[:, :current_num_mask]\n",
        "# Create the mask tensor\n",
        "mask = torch.zeros((batch_size, max_patches), dtype=torch.bool)\n",
        "mask.scatter_(1, random_indices, True)\n",
        "\n",
        "#Mask\n",
        "masked_patches[mask] = num_tokens - 1  # Replace masked patches with the mask token\n",
        "\n",
        "# Move to device\n",
        "masked_patches, patch_indices, mask = (\n",
        "    masked_patches.to(device),\n",
        "    patch_indices.to(device),\n",
        "    mask.to(device),\n",
        ")\n",
        "\n",
        "#Get the logits of the masked patches\n",
        "logits = model(masked_patches) # (batch_size,max_patches,num_tokens - 1)\n",
        "# Isolate the masked patches\n",
        "# Get the indices of True values\n",
        "indices = mask.nonzero(as_tuple=True)  # Returns indices where mask is True\n",
        "# Extract logits at masked positions while maintaining row-wise structure\n",
        "masked_logits = logits[indices[0], indices[1]]  # Extracts all True-index logits\n",
        "masked_patch_indices = patch_indices[indices[0], indices[1]]  # Extracts all True-index patch indices\n",
        "# Reshape to [batch_size, num_masked_patches, num_classes]\n",
        "masked_logits = masked_logits.view(batch_size, current_num_mask, -1)  # (batch_size, current_num_mask, num_tokens-1)\n",
        "masked_patch_indices = masked_patch_indices.view(batch_size, current_num_mask) #(batch_size, current_num_mask)\n",
        "masked_probs = torch.softmax(masked_logits, dim=-1) # (batch_size,current_num_mask,num_tokens-1)\n",
        "samples = torch.multinomial(masked_probs.view(-1, num_tokens-1), num_samples=1)\n",
        "# Get the probabilites of the samples\n",
        "prob_samples = torch.gather(masked_probs.view(-1, num_tokens-1), 1, samples.view(-1, 1))\n",
        "# Find the argmax\n",
        "max_prob = torch.argmax(prob_samples, dim=0)\n",
        "best_sample = samples[0][max_prob]\n",
        "best_sample_idx = torch.nonzero(mask)\n",
        "print(\"Best sample: \", best_sample)\n",
        "print(\"Best sample index: \", best_sample_idx)\n",
        "#reconstructed_patches = masked_patches.clone()\n"
      ],
      "metadata": {
        "id": "he03XI7fMik5",
        "outputId": "d73b39eb-d24e-4431-98a8-0478ddb535d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-be611c768d9e>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"vision_transformer_final_balanced.pth\"))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-be611c768d9e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vision_transformer_final_balanced.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the first image from the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Dataset and DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m                 return _load(\n\u001b[0m\u001b[1;32m   1361\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m                     \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m             typed_storage = load_tensor(\n\u001b[0m\u001b[1;32m   1813\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m             \u001b[0m_internal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \"\"\"\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     ) -> Union[_StorageBase, TypedStorage]:\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m     87\u001b[0m             ), f\"sparse storage is not supported for {device.type.upper()} tensors\"\n\u001b[1;32m     88\u001b[0m             \u001b[0muntyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0muntyped_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0muntyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}